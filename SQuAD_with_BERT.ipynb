{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SQuAD with BERT",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1URnO9y3zKGaPPRUXojYN_WXz9mh-MzVT",
      "authorship_tag": "ABX9TyN8ba0ASDWffcu5mfh/QOFS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vrushaligirkar/NLP-Project-QA-system/blob/master/SQuAD_with_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h46ABPmNgs9_",
        "colab_type": "code",
        "outputId": "265f73da-bf38-4a94-e70c-14356024cd30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "source": [
        "!pip install pytorch-transformers==1.0.0"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-transformers==1.0.0 in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers==1.0.0) (4.38.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers==1.0.0) (2019.12.20)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers==1.0.0) (0.1.86)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers==1.0.0) (2.21.0)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers==1.0.0) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers==1.0.0) (1.18.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers==1.0.0) (1.12.40)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers==1.0.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers==1.0.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers==1.0.0) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers==1.0.0) (2.8)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers==1.0.0) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers==1.0.0) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.40 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers==1.0.0) (1.15.40)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.40->boto3->pytorch-transformers==1.0.0) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.40->boto3->pytorch-transformers==1.0.0) (0.15.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.16.0,>=1.15.40->boto3->pytorch-transformers==1.0.0) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgzx9i8xCfFV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "5a486f13-4035-483c-8564-6cdb29089e5c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_tucTFKQBuV",
        "colab_type": "code",
        "outputId": "ac594c56-b0f6-4114-cc22-25272d45cf16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%%writefile setup.sh\n",
        "\n",
        "git clone https://github.com/NVIDIA/apex\n",
        "pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing setup.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjNF2poJu0VO",
        "colab_type": "code",
        "outputId": "7a95f84d-ba1a-4147-db1b-7fad5ac7e1ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!git clone https://github.com/NVIDIA/apex"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'apex' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBJIkd3JAloe",
        "colab_type": "code",
        "outputId": "4f2528a8-5452-4d4f-cfcc-c914e97c85a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd apex\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/apex/apex\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Oe95BN8AoPe",
        "colab_type": "code",
        "outputId": "b218b7cd-3c97-4429-defc-8d96b479e610",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!python setup.py install"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python3: can't open file 'setup.py': [Errno 2] No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wc5ExipKQL9s",
        "colab_type": "code",
        "outputId": "c8c32607-e400-4292-b1b7-ec9f019411aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!sh setup.sh"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sh: 0: Can't open setup.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYJgnLzRgzpt",
        "colab_type": "code",
        "outputId": "92e80e8d-ecd2-4a4b-d9c3-bb0d6387d3bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "!pip install Flask==1.1.1"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Flask==1.1.1 in /usr/local/lib/python3.6/dist-packages (1.1.1)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask==1.1.1) (2.11.2)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask==1.1.1) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask==1.1.1) (1.0.1)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask==1.1.1) (7.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask==1.1.1) (1.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_u0IJJY-g4ef",
        "colab_type": "code",
        "outputId": "ab1920f8-bddc-4796-d576-49a48379a248",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "!pip install Flask-Cors==3.0.8"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Flask-Cors==3.0.8 in /usr/local/lib/python3.6/dist-packages (3.0.8)\n",
            "Requirement already satisfied: Flask>=0.9 in /usr/local/lib/python3.6/dist-packages (from Flask-Cors==3.0.8) (1.1.1)\n",
            "Requirement already satisfied: Six in /usr/local/lib/python3.6/dist-packages (from Flask-Cors==3.0.8) (1.12.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.9->Flask-Cors==3.0.8) (1.0.1)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.9->Flask-Cors==3.0.8) (2.11.2)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.9->Flask-Cors==3.0.8) (7.1.1)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.9->Flask-Cors==3.0.8) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=0.9->Flask-Cors==3.0.8) (1.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bInVIUktkdn9",
        "colab_type": "code",
        "outputId": "c9a2d379-6315-4ff2-a084-8832feb638e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "!pip install tensorboardX"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.6/dist-packages (2.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.18.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (46.1.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VT7NpOAdmqtt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfcUnSdplnoi",
        "colab_type": "code",
        "outputId": "540dda37-bceb-43dc-f3d9-864cbfeb5f1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-ed2fd71b4a2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'files' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6kRLN_ehB6D",
        "colab_type": "code",
        "outputId": "29230848-405c-45e5-b600-724e1418f240",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import argparse\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "import glob\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
        "                              TensorDataset)\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "from tensorboardX import SummaryWriter\n",
        "\n",
        "from pytorch_transformers import (WEIGHTS_NAME, BertConfig,\n",
        "                                  BertForQuestionAnswering, BertTokenizer,\n",
        "                                  XLMConfig, XLMForQuestionAnswering,\n",
        "                                  XLMTokenizer, XLNetConfig,\n",
        "                                  XLNetForQuestionAnswering,\n",
        "                                  XLNetTokenizer)\n",
        "\n",
        "from pytorch_transformers import AdamW, WarmupLinearSchedule\n",
        "\n",
        "from utils_squad import (read_squad_examples, convert_examples_to_features,\n",
        "                         RawResult, write_predictions,\n",
        "                         RawResultExtended, write_predictions_extended)\n",
        "\n",
        "from utils_squad_evaluate import EVAL_OPTS, main as evaluate_on_squad\n",
        "logger = logging.getLogger(__name__)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-1b0cad4043ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_transformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdamW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWarmupLinearSchedule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m from utils_squad import (read_squad_examples, convert_examples_to_features,\n\u001b[0m\u001b[1;32m     28\u001b[0m                          \u001b[0mRawResult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_predictions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                          RawResultExtended, write_predictions_extended)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils_squad'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQO2ntG9lNfZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ALL_MODELS = sum((tuple(conf.pretrained_config_archive_map.keys()) \\\n",
        "                  for conf in (BertConfig, XLNetConfig, XLMConfig)), ())\n",
        "\n",
        "MODEL_CLASSES = {\n",
        "    'bert': (BertConfig, BertForQuestionAnswering, BertTokenizer),\n",
        "    'xlnet': (XLNetConfig, XLNetForQuestionAnswering, XLNetTokenizer),\n",
        "    'xlm': (XLMConfig, XLMForQuestionAnswering, XLMTokenizer),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKJ5sGpflQ7f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def set_seed(args):\n",
        "    random.seed(args.seed)\n",
        "    np.random.seed(args.seed)\n",
        "    torch.manual_seed(args.seed)\n",
        "    if args.n_gpu > 0:\n",
        "        torch.cuda.manual_seed_all(args.seed)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAqm2a9SlTk1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_list(tensor):\n",
        "    return tensor.detach().cpu().tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ubh-xw1Yld6Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(args, train_dataset, model, tokenizer):\n",
        "    \"\"\" Train the model \"\"\"\n",
        "    if args.local_rank in [-1, 0]:\n",
        "        tb_writer = SummaryWriter()\n",
        "\n",
        "    args.train_batch_size = args.per_gpu_train_batch_size * max(1, args.n_gpu)\n",
        "    train_sampler = RandomSampler(train_dataset) if args.local_rank == -1 else DistributedSampler(train_dataset)\n",
        "    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=args.train_batch_size)\n",
        "\n",
        "    if args.max_steps > 0:\n",
        "        t_total = args.max_steps\n",
        "        args.num_train_epochs = args.max_steps // (len(train_dataloader) // args.gradient_accumulation_steps) + 1\n",
        "    else:\n",
        "        t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n",
        "\n",
        "    # Prepare optimizer and schedule (linear warmup and decay)\n",
        "    no_decay = ['bias', 'LayerNorm.weight']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': args.weight_decay},\n",
        "        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "        ]\n",
        "    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n",
        "    scheduler = WarmupLinearSchedule(optimizer, warmup_steps=args.warmup_steps, t_total=t_total)\n",
        "    if args.fp16:\n",
        "        try:\n",
        "            from apex import amp\n",
        "        except ImportError:\n",
        "            raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")\n",
        "        model, optimizer = amp.initialize(model, optimizer, opt_level=args.fp16_opt_level)\n",
        "        #model = TransformerModel('bert', 'bert-base-cased', use_cuda=False, args={'fp16': False})\n",
        "\n",
        "    # multi-gpu training (should be after apex fp16 initialization)\n",
        "    if args.n_gpu > 1:\n",
        "        model = torch.nn.DataParallel(model)\n",
        "\n",
        "    # Distributed training (should be after apex fp16 initialization)\n",
        "    if args.local_rank != -1:\n",
        "        model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.local_rank],\n",
        "                                                          output_device=args.local_rank,\n",
        "                                                          find_unused_parameters=True)\n",
        "\n",
        "    # Train!\n",
        "    logger.info(\"***** Running training *****\")\n",
        "    logger.info(\"  Num examples = %d\", len(train_dataset))\n",
        "    logger.info(\"  Num Epochs = %d\", args.num_train_epochs)\n",
        "    logger.info(\"  Instantaneous batch size per GPU = %d\", args.per_gpu_train_batch_size)\n",
        "    logger.info(\"  Total train batch size (w. parallel, distributed & accumulation) = %d\",\n",
        "                   args.train_batch_size * args.gradient_accumulation_steps * (torch.distributed.get_world_size() if args.local_rank != -1 else 1))\n",
        "    logger.info(\"  Gradient Accumulation steps = %d\", args.gradient_accumulation_steps)\n",
        "    logger.info(\"  Total optimization steps = %d\", t_total)\n",
        "\n",
        "    global_step = 0\n",
        "    tr_loss, logging_loss = 0.0, 0.0\n",
        "    model.zero_grad()\n",
        "    train_iterator = trange(int(args.num_train_epochs), desc=\"Epoch\", disable=args.local_rank not in [-1, 0])\n",
        "    set_seed(args)  # Added here for reproductibility (even between python 2 and 3)\n",
        "    for _ in train_iterator:\n",
        "        epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=args.local_rank not in [-1, 0])\n",
        "        for step, batch in enumerate(epoch_iterator):\n",
        "            model.train()\n",
        "            batch = tuple(t.to(args.device) for t in batch)\n",
        "            inputs = {'input_ids':       batch[0],\n",
        "                      'attention_mask':  batch[1], \n",
        "                      'token_type_ids':  None if args.model_type == 'xlm' else batch[2],  \n",
        "                      'start_positions': batch[3], \n",
        "                      'end_positions':   batch[4]}\n",
        "            if args.model_type in ['xlnet', 'xlm']:\n",
        "                inputs.update({'cls_index': batch[5],\n",
        "                               'p_mask':    batch[6]})\n",
        "            outputs = model(**inputs)\n",
        "            loss = outputs[0]  # model outputs are always tuple in pytorch-transformers (see doc)\n",
        "\n",
        "            if args.n_gpu > 1:\n",
        "                loss = loss.mean() # mean() to average on multi-gpu parallel (not distributed) training\n",
        "            if args.gradient_accumulation_steps > 1:\n",
        "                loss = loss / args.gradient_accumulation_steps\n",
        "\n",
        "            if args.fp16:\n",
        "                with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
        "                    scaled_loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args.max_grad_norm)\n",
        "            else:\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
        "\n",
        "            tr_loss += loss.item()\n",
        "            if (step + 1) % args.gradient_accumulation_steps == 0:\n",
        "                scheduler.step()  # Update learning rate schedule\n",
        "                optimizer.step()\n",
        "                model.zero_grad()\n",
        "                global_step += 1\n",
        "\n",
        "                if args.local_rank in [-1, 0] and args.logging_steps > 0 and global_step % args.logging_steps == 0:\n",
        "                    # Log metrics\n",
        "                    if args.local_rank == -1 and args.evaluate_during_training:  # Only evaluate when single GPU otherwise metrics may not average well\n",
        "                        results = evaluate(args, model, tokenizer)\n",
        "                        for key, value in results.items():\n",
        "                            tb_writer.add_scalar('eval_{}'.format(key), value, global_step)\n",
        "                    tb_writer.add_scalar('lr', scheduler.get_lr()[0], global_step)\n",
        "                    tb_writer.add_scalar('loss', (tr_loss - logging_loss)/args.logging_steps, global_step)\n",
        "                    logging_loss = tr_loss\n",
        "\n",
        "                if args.local_rank in [-1, 0] and args.save_steps > 0 and global_step % args.save_steps == 0:\n",
        "                    # Save model checkpoint\n",
        "                    output_dir = os.path.join(args.output_dir, 'checkpoint-{}'.format(global_step))\n",
        "                    if not os.path.exists(output_dir):\n",
        "                        os.makedirs(output_dir)\n",
        "                    model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "                    model_to_save.save_pretrained(output_dir)\n",
        "                    torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n",
        "                    logger.info(\"Saving model checkpoint to %s\", output_dir)\n",
        "\n",
        "            if args.max_steps > 0 and global_step > args.max_steps:\n",
        "                epoch_iterator.close()\n",
        "                break\n",
        "        if args.max_steps > 0 and global_step > args.max_steps:\n",
        "            train_iterator.close()\n",
        "            break\n",
        "\n",
        "    if args.local_rank in [-1, 0]:\n",
        "        tb_writer.close()\n",
        "\n",
        "    return global_step, tr_loss / global_step"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HL838MDeljOL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(args, model, tokenizer, prefix=\"\"):\n",
        "    dataset, examples, features = load_and_cache_examples(args, tokenizer, evaluate=True, output_examples=True)\n",
        "\n",
        "    if not os.path.exists(args.output_dir) and args.local_rank in [-1, 0]:\n",
        "        os.makedirs(args.output_dir)\n",
        "\n",
        "    args.eval_batch_size = args.per_gpu_eval_batch_size * max(1, args.n_gpu)\n",
        "    # Note that DistributedSampler samples randomly\n",
        "    eval_sampler = SequentialSampler(dataset) if args.local_rank == -1 else DistributedSampler(dataset)\n",
        "    eval_dataloader = DataLoader(dataset, sampler=eval_sampler, batch_size=args.eval_batch_size)\n",
        "\n",
        "    # Eval!\n",
        "    logger.info(\"***** Running evaluation {} *****\".format(prefix))\n",
        "    logger.info(\"  Num examples = %d\", len(dataset))\n",
        "    logger.info(\"  Batch size = %d\", args.eval_batch_size)\n",
        "    all_results = []\n",
        "    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
        "        model.eval()\n",
        "        batch = tuple(t.to(args.device) for t in batch)\n",
        "        with torch.no_grad():\n",
        "            inputs = {'input_ids':      batch[0],\n",
        "                      'attention_mask': batch[1],\n",
        "                      'token_type_ids': None if args.model_type == 'xlm' else batch[2]  # XLM don't use segment_ids\n",
        "                      }\n",
        "            example_indices = batch[3]\n",
        "            if args.model_type in ['xlnet', 'xlm']:\n",
        "                inputs.update({'cls_index': batch[4],\n",
        "                               'p_mask':    batch[5]})\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        for i, example_index in enumerate(example_indices):\n",
        "            eval_feature = features[example_index.item()]\n",
        "            unique_id = int(eval_feature.unique_id)\n",
        "            if args.model_type in ['xlnet', 'xlm']:\n",
        "                # XLNet uses a more complex post-processing procedure\n",
        "                result = RawResultExtended(unique_id            = unique_id,\n",
        "                                           start_top_log_probs  = to_list(outputs[0][i]),\n",
        "                                           start_top_index      = to_list(outputs[1][i]),\n",
        "                                           end_top_log_probs    = to_list(outputs[2][i]),\n",
        "                                           end_top_index        = to_list(outputs[3][i]),\n",
        "                                           cls_logits           = to_list(outputs[4][i]))\n",
        "            else:\n",
        "                result = RawResult(unique_id    = unique_id,\n",
        "                                   start_logits = to_list(outputs[0][i]),\n",
        "                                   end_logits   = to_list(outputs[1][i]))\n",
        "            all_results.append(result)\n",
        "\n",
        "    # Compute predictions\n",
        "    output_prediction_file = os.path.join(args.output_dir, \"predictions_{}.json\".format(prefix))\n",
        "    output_nbest_file = os.path.join(args.output_dir, \"nbest_predictions_{}.json\".format(prefix))\n",
        "    if args.version_2_with_negative:\n",
        "        output_null_log_odds_file = os.path.join(args.output_dir, \"null_odds_{}.json\".format(prefix))\n",
        "    else:\n",
        "        output_null_log_odds_file = None\n",
        "\n",
        "    if args.model_type in ['xlnet', 'xlm']:\n",
        "        # XLNet uses a more complex post-processing procedure\n",
        "        write_predictions_extended(examples, features, all_results, args.n_best_size,\n",
        "                        args.max_answer_length, output_prediction_file,\n",
        "                        output_nbest_file, output_null_log_odds_file, args.predict_file,\n",
        "                        model.config.start_n_top, model.config.end_n_top,\n",
        "                        args.version_2_with_negative, tokenizer, args.verbose_logging)\n",
        "    else:\n",
        "        write_predictions(examples, features, all_results, args.n_best_size,\n",
        "                        args.max_answer_length, args.do_lower_case, output_prediction_file,\n",
        "                        output_nbest_file, output_null_log_odds_file, args.verbose_logging,\n",
        "                        args.version_2_with_negative, args.null_score_diff_threshold)\n",
        "\n",
        "    # Evaluate with the official SQuAD script\n",
        "    evaluate_options = EVAL_OPTS(data_file=args.predict_file,\n",
        "                                 pred_file=output_prediction_file,\n",
        "                                 na_prob_file=output_null_log_odds_file)\n",
        "    results = evaluate_on_squad(evaluate_options)\n",
        "    return results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WF9m4jrlttS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_and_cache_examples(args, tokenizer, evaluate=False, output_examples=False):\n",
        "    # Load data features from cache or dataset file\n",
        "    input_file = args.predict_file if evaluate else args.train_file\n",
        "    cached_features_file = os.path.join(os.path.dirname(input_file), 'cached_{}_{}_{}'.format(\n",
        "        'dev' if evaluate else 'train',\n",
        "        list(filter(None, args.model_name_or_path.split('/'))).pop(),\n",
        "        str(args.max_seq_length)))\n",
        "    if os.path.exists(cached_features_file) and not args.overwrite_cache and not output_examples:\n",
        "        logger.info(\"Loading features from cached file %s\", cached_features_file)\n",
        "        features = torch.load(cached_features_file)\n",
        "    else:\n",
        "        logger.info(\"Creating features from dataset file at %s\", input_file)\n",
        "        examples = read_squad_examples(input_file=input_file,\n",
        "                                                is_training=not evaluate,\n",
        "                                                version_2_with_negative=args.version_2_with_negative)\n",
        "        features = convert_examples_to_features(examples=examples,\n",
        "                                                tokenizer=tokenizer,\n",
        "                                                max_seq_length=args.max_seq_length,\n",
        "                                                doc_stride=args.doc_stride,\n",
        "                                                max_query_length=args.max_query_length,\n",
        "                                                is_training=not evaluate)\n",
        "        if args.local_rank in [-1, 0]:\n",
        "            logger.info(\"Saving features into cached file %s\", cached_features_file)\n",
        "            torch.save(features, cached_features_file)\n",
        "\n",
        "    # Convert to Tensors and build dataset\n",
        "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
        "    all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
        "    all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
        "    all_cls_index = torch.tensor([f.cls_index for f in features], dtype=torch.long)\n",
        "    all_p_mask = torch.tensor([f.p_mask for f in features], dtype=torch.float)\n",
        "    if evaluate:\n",
        "        all_example_index = torch.arange(all_input_ids.size(0), dtype=torch.long)\n",
        "        dataset = TensorDataset(all_input_ids, all_input_mask, all_segment_ids,\n",
        "                                all_example_index, all_cls_index, all_p_mask)\n",
        "    else:\n",
        "        all_start_positions = torch.tensor([f.start_position for f in features], dtype=torch.long)\n",
        "        all_end_positions = torch.tensor([f.end_position for f in features], dtype=torch.long)\n",
        "        dataset = TensorDataset(all_input_ids, all_input_mask, all_segment_ids,\n",
        "                                all_start_positions, all_end_positions,\n",
        "                                all_cls_index, all_p_mask)\n",
        "\n",
        "    if output_examples:\n",
        "        return dataset, examples, features\n",
        "    return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aPb1-EG758k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_file = '/content/drive/My Drive/train-v2.0.json'\n",
        "dev_file = '/content/drive/My Drive/dev-v2.0.json'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNwvPMSd8Au1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Args:\n",
        "    def __init__(self):\n",
        "        \n",
        "        self.train_file = train_file\n",
        "        self.predict_file = dev_file\n",
        "        self.model_type = 'bert'\n",
        "        self.model_name_or_path = 'bert-large-uncased-whole-word-masking'\n",
        "        self.output_dir = '/content/'    \n",
        "        self.config_name = \"\"\n",
        "        self.tokenizer_name = \"\"\n",
        "        self.cache_dir = \"\"\n",
        "\n",
        "        self.version_2_with_negative = True\n",
        "        self.null_score_diff_threshold = 0.0\n",
        "\n",
        "        self.max_seq_length = 384\n",
        "        self.doc_stride = 128\n",
        "        self.max_query_length = 64\n",
        "        self.do_train = True\n",
        "        self.do_eval = True\n",
        "        self.evaluate_during_training = True\n",
        "        self.do_lower_case = True\n",
        "\n",
        "        self.per_gpu_eval_batch_size = 3\n",
        "        self.per_gpu_train_batch_size  = 3\n",
        "        self.learning_rate = 3e-5\n",
        "        self.gradient_accumulation_steps = 1\n",
        "        self.weight_decay = 0.0\n",
        "        self.adam_epsilon = 1e-8\n",
        "        self.max_grad_norm = 1.0\n",
        "        self.num_train_epochs = 2\n",
        "        self.max_steps = -1\n",
        "        self.warmup_steps = 0\n",
        "        self.n_best_size = 20\n",
        "        self.max_answer_length = 30\n",
        "        self.verbose_logging  = True\n",
        "\n",
        "        self.logging_steps = 50\n",
        "        self.save_steps = 50\n",
        "        self.eval_all_checkpoints = True\n",
        "        self.no_cuda = True\n",
        "        self.overwrite_output_dir = True\n",
        "        self.overwrite_cache = True\n",
        "        self.seed = 42\n",
        "\n",
        "        self.local_rank = -1\n",
        "        self.fp16 = True\n",
        "        self.fp16_opt_level = 'O1'\n",
        "        self.server_ip = \"\"\n",
        "        self.server_port = \"\"\n",
        "\n",
        "\n",
        "\n",
        "#args['--train_file'] = train_file\n",
        "#args['--predict_file'] = dev_file\n",
        "#args['--model_type'] = 'bert'\n",
        "#args['--model_name_or_path'] = 'bert-large-uncased-whole-word-masking'\n",
        "#args['--output_dir'] = '/content/'\n",
        "\n",
        "#args['--config_name'] = \"\"\n",
        "#args['--tokenizer_name'] = \"\"\n",
        "#args['--cache_dir'] = \"\"\n",
        "\n",
        "#args['--version_2_with_negative'] = True\n",
        "#args['--null_score_diff_threshold'] = 0.0\n",
        "\n",
        "#args['--max_seq_length'] = 384\n",
        "#args['--doc_stride'] = 128\n",
        "#args['--max_query_length'] = 64\n",
        "#args['--do_train'] = True\n",
        "#args['--do_eval'] = True\n",
        "#args['--evaluate_during_training'] = True\n",
        "#args['--do_lower_case'] = True\n",
        "#args['--per_gpu_eval_batch_size'] = 3\n",
        "#args['--per_gpu_train_batch_size'] = 3\n",
        "#args['--learning_rate'] = 3e-5\n",
        "#args['--gradient_accumulation_steps'] = 1\n",
        "#args['--weight_decay'] = 0.0\n",
        "#args['--adam_epsilon'] = 1e-8\n",
        "#args['--max_grad_norm'] = 1.0\n",
        "#args['--num_train_epochs'] = 2\n",
        "#args['--max_steps'] = -1\n",
        "#args['--warmup_steps'] = 0\n",
        "#args['--n_best_size'] = 20\n",
        "#args['--max_answer_length'] = 30\n",
        "#args['--verbose_logging'] = True\n",
        "#args['--logging_steps'] = 50\n",
        "#args['--save_steps'] = 50\n",
        "#args['--eval_all_checkpoints'] = True\n",
        "#args['--no_cuda'] = True\n",
        "#args['--overwrite_output_dir'] = True\n",
        "#args['--overwrite_cache'] = True\n",
        "#args['--seed'] = 42\n",
        "\n",
        "#args['--local_rank'] = -1\n",
        "#args['--fp16'] = True\n",
        "#args['--fp16_opt_level'] = 'O1'\n",
        "#args['--server_ip'] = \"\"\n",
        "#args['--server_port'] = \"\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5_Tc2zUlyUI",
        "colab_type": "code",
        "outputId": "d480dca4-ddcd-49ee-ae6b-e98bbab51cc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def main():\n",
        "    \n",
        "    args = Args()\n",
        "    if os.path.exists(args.output_dir) and os.listdir(args.output_dir) and args.do_train and not args.overwrite_output_dir:\n",
        "        raise ValueError(\"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(args.output_dir))\n",
        "\n",
        "    # Setup distant debugging if needed\n",
        "    if args.server_ip and args.server_port:\n",
        "        # Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script\n",
        "        import ptvsd\n",
        "        print(\"Waiting for debugger attach\")\n",
        "        ptvsd.enable_attach(address=(args.server_ip, args.server_port), redirect_output=True)\n",
        "        ptvsd.wait_for_attach()\n",
        "\n",
        "    # Setup CUDA, GPU & distributed training\n",
        "    if args.local_rank == -1 or args.no_cuda:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")\n",
        "        args.n_gpu = torch.cuda.device_count()\n",
        "    else:  # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
        "        torch.cuda.set_device(args.local_rank)\n",
        "        device = torch.device(\"cuda\", args.local_rank)\n",
        "        torch.distributed.init_process_group(backend='nccl')\n",
        "        args.n_gpu = 1\n",
        "    args.device = device\n",
        "\n",
        "    # Setup logging\n",
        "    logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
        "                        datefmt = '%m/%d/%Y %H:%M:%S',\n",
        "                        level = logging.INFO if args.local_rank in [-1, 0] else logging.WARN)\n",
        "    logger.warning(\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\",\n",
        "                    args.local_rank, device, args.n_gpu, bool(args.local_rank != -1), args.fp16)\n",
        "\n",
        "    # Set seed\n",
        "    set_seed(args)\n",
        "\n",
        "    # Load pretrained model and tokenizer\n",
        "    if args.local_rank not in [-1, 0]:\n",
        "        torch.distributed.barrier()  # Make sure only the first process in distributed training will download model & vocab\n",
        "\n",
        "    args.model_type = args.model_type.lower()\n",
        "    config_class, model_class, tokenizer_class = MODEL_CLASSES[args.model_type]\n",
        "    config = config_class.from_pretrained(args.config_name if args.config_name else args.model_name_or_path)\n",
        "    tokenizer = tokenizer_class.from_pretrained(args.tokenizer_name if args.tokenizer_name else args.model_name_or_path, do_lower_case=args.do_lower_case)\n",
        "    model = model_class.from_pretrained(args.model_name_or_path, from_tf=bool('.ckpt' in args.model_name_or_path), config=config)\n",
        "\n",
        "    if args.local_rank == 0:\n",
        "        torch.distributed.barrier()  # Make sure only the first process in distributed training will download model & vocab\n",
        "\n",
        "    model.to(args.device)\n",
        "\n",
        "    logger.info(\"Training/evaluation parameters %s\", args)\n",
        "\n",
        "    # Training\n",
        "    if args.do_train:\n",
        "        train_dataset = load_and_cache_examples(args, tokenizer, evaluate=False, output_examples=False)\n",
        "        global_step, tr_loss = train(args, train_dataset, model, tokenizer)\n",
        "        logger.info(\" global_step = %s, average loss = %s\", global_step, tr_loss)\n",
        "\n",
        "\n",
        "    # Save the trained model and the tokenizer\n",
        "    if args.local_rank == -1 or torch.distributed.get_rank() == 0:\n",
        "        # Create output directory if needed\n",
        "        if not os.path.exists(args.output_dir) and args.local_rank in [-1, 0]:\n",
        "            os.makedirs(args.output_dir)\n",
        "\n",
        "        logger.info(\"Saving model checkpoint to %s\", args.output_dir)\n",
        "        # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "        # They can then be reloaded using `from_pretrained()`\n",
        "        model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "        model_to_save.save_pretrained(args.output_dir)\n",
        "        tokenizer.save_pretrained(args.output_dir)\n",
        "\n",
        "        # Good practice: save your training arguments together with the trained model\n",
        "        torch.save(args, os.path.join(args.output_dir, 'training_args.bin'))\n",
        "\n",
        "        # Load a trained model and vocabulary that you have fine-tuned\n",
        "        model = model_class.from_pretrained(args.output_dir)\n",
        "        tokenizer = tokenizer_class.from_pretrained(args.output_dir)\n",
        "        model.to(args.device)\n",
        "\n",
        "\n",
        "    # Evaluation - we can ask to evaluate all the checkpoints (sub-directories) in a directory\n",
        "    results = {}\n",
        "    if args.do_eval and args.local_rank in [-1, 0]:\n",
        "        checkpoints = [args.output_dir]\n",
        "        if args.eval_all_checkpoints:\n",
        "            checkpoints = list(os.path.dirname(c) for c in sorted(glob.glob(args.output_dir + '/**/' + WEIGHTS_NAME, recursive=True)))\n",
        "            logging.getLogger(\"pytorch_transformers.modeling_utils\").setLevel(logging.WARN)  # Reduce model loading logs\n",
        "\n",
        "        logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n",
        "\n",
        "        for checkpoint in checkpoints:\n",
        "            # Reload the model\n",
        "            global_step = checkpoint.split('-')[-1] if len(checkpoints) > 1 else \"\"\n",
        "            model = model_class.from_pretrained(checkpoint)\n",
        "            model.to(args.device)\n",
        "\n",
        "            # Evaluate\n",
        "            result = evaluate(args, model, tokenizer, prefix=global_step)\n",
        "\n",
        "            result = dict((k + ('_{}'.format(global_step) if global_step else ''), v) for k, v in result.items())\n",
        "            results.update(result)\n",
        "\n",
        "    logger.info(\"Results: {}\".format(results))\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "04/23/2020 18:21:02 - WARNING - __main__ -   Process rank: -1, device: cpu, n_gpu: 0, distributed training: False, 16-bits training: True\n",
            "04/23/2020 18:21:02 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-whole-word-masking-config.json from cache at /root/.cache/torch/pytorch_transformers/acdf0fd9c7a1b157516c5c0434216c72438b384fb6ddeeaa20d67e83d1fef81f.fc076a4d5f1edf25ea3a2bd66e9f6f295dcd64c81dfef5b3f5a3eb2a82751ad1\n",
            "04/23/2020 18:21:02 - INFO - pytorch_transformers.modeling_utils -   Model config {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"num_labels\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "04/23/2020 18:21:02 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-whole-word-masking-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/b3a6b2c6d7ea2ffa06d0e7577c1e88b94fad470ae0f060a4ffef3fe0bdf86730.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "04/23/2020 18:21:03 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-whole-word-masking-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/66cc7a7501e3499efedc37e47b3a613e0d3d8d0a51c66224c69f0c669b52dcfb.ae11cc7f2a26b857b76b404a908c7abad793f88bf8ad95caecff154da87994b1\n",
            "04/23/2020 18:21:36 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForQuestionAnswering not initialized from pretrained model: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "04/23/2020 18:21:36 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForQuestionAnswering: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "04/23/2020 18:21:36 - INFO - __main__ -   Training/evaluation parameters <__main__.Args object at 0x7f2d0504cd68>\n",
            "04/23/2020 18:21:36 - INFO - __main__ -   Creating features from dataset file at /content/drive/My Drive/train-v2.0.json\n",
            "04/23/2020 18:21:45 - INFO - utils_squad -   *** Example ***\n",
            "04/23/2020 18:21:45 - INFO - utils_squad -   unique_id: 1000000000\n",
            "04/23/2020 18:21:45 - INFO - utils_squad -   example_index: 0\n",
            "04/23/2020 18:21:45 - INFO - utils_squad -   doc_span_index: 0\n",
            "04/23/2020 18:21:45 - INFO - utils_squad -   tokens: [CLS] when did beyonce start becoming popular ? [SEP] beyonce gi ##selle knowles - carter ( / bi ##ː ##ˈ ##j ##ɒ ##nse ##ɪ / bee - yo ##n - say ) ( born september 4 , 1981 ) is an american singer , songwriter , record producer and actress . born and raised in houston , texas , she performed in various singing and dancing competitions as a child , and rose to fame in the late 1990s as lead singer of r & b girl - group destiny ' s child . managed by her father , mathew knowles , the group became one of the world ' s best - selling girl groups of all time . their hiatus saw the release of beyonce ' s debut album , dangerously in love ( 2003 ) , which established her as a solo artist worldwide , earned five grammy awards and featured the billboard hot 100 number - one singles \" crazy in love \" and \" baby boy \" . [SEP]\n",
            "04/23/2020 18:21:45 - INFO - utils_squad -   token_to_orig_map: 9:0 10:1 11:1 12:2 13:2 14:2 15:3 16:3 17:3 18:3 19:3 20:3 21:3 22:3 23:3 24:3 25:4 26:4 27:4 28:4 29:4 30:4 31:4 32:5 33:5 34:6 35:7 36:7 37:8 38:8 39:9 40:10 41:11 42:12 43:12 44:13 45:13 46:14 47:15 48:16 49:17 50:17 51:18 52:19 53:20 54:21 55:22 56:22 57:23 58:23 59:24 60:25 61:26 62:27 63:28 64:29 65:30 66:31 67:32 68:33 69:34 70:34 71:35 72:36 73:37 74:38 75:39 76:40 77:41 78:42 79:43 80:44 81:45 82:46 83:47 84:47 85:47 86:48 87:48 88:48 89:49 90:49 91:49 92:50 93:50 94:51 95:52 96:53 97:54 98:54 99:55 100:56 101:56 102:57 103:58 104:59 105:60 106:61 107:62 108:63 109:63 110:63 111:64 112:64 113:64 114:65 115:66 116:67 117:68 118:69 119:69 120:70 121:71 122:72 123:73 124:74 125:75 126:76 127:76 128:76 129:77 130:78 131:78 132:79 133:80 134:81 135:82 136:82 137:82 138:82 139:83 140:84 141:85 142:86 143:87 144:88 145:89 146:90 147:90 148:91 149:92 150:93 151:94 152:95 153:96 154:97 155:98 156:99 157:100 158:101 159:101 160:101 161:102 162:103 163:103 164:104 165:105 166:105 167:106 168:107 169:107 170:108 171:108 172:108\n",
            "04/23/2020 18:21:45 - INFO - utils_squad -   token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True\n",
            "04/23/2020 18:21:45 - INFO - utils_squad -   input_ids: 101 2043 2106 20773 2707 3352 2759 1029 102 20773 21025 19358 22815 1011 5708 1006 1013 12170 23432 29715 3501 29678 12325 29685 1013 10506 1011 10930 2078 1011 2360 1007 1006 2141 2244 1018 1010 3261 1007 2003 2019 2137 3220 1010 6009 1010 2501 3135 1998 3883 1012 2141 1998 2992 1999 5395 1010 3146 1010 2016 2864 1999 2536 4823 1998 5613 6479 2004 1037 2775 1010 1998 3123 2000 4476 1999 1996 2397 4134 2004 2599 3220 1997 1054 1004 1038 2611 1011 2177 10461 1005 1055 2775 1012 3266 2011 2014 2269 1010 25436 22815 1010 1996 2177 2150 2028 1997 1996 2088 1005 1055 2190 1011 4855 2611 2967 1997 2035 2051 1012 2037 14221 2387 1996 2713 1997 20773 1005 1055 2834 2201 1010 20754 1999 2293 1006 2494 1007 1010 2029 2511 2014 2004 1037 3948 3063 4969 1010 3687 2274 8922 2982 1998 2956 1996 4908 2980 2531 2193 1011 2028 3895 1000 4689 1999 2293 1000 1998 1000 3336 2879 1000 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:45 - INFO - utils_squad -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:45 - INFO - utils_squad -   segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:45 - INFO - utils_squad -   start_position: 75\n",
            "04/23/2020 18:21:45 - INFO - utils_squad -   end_position: 78\n",
            "04/23/2020 18:21:45 - INFO - utils_squad -   answer: in the late 1990s\n",
            "04/23/2020 18:21:45 - INFO - utils_squad -   *** Example ***\n",
            "04/23/2020 18:21:45 - INFO - utils_squad -   unique_id: 1000000001\n",
            "04/23/2020 18:21:45 - INFO - utils_squad -   example_index: 1\n",
            "04/23/2020 18:21:45 - INFO - utils_squad -   doc_span_index: 0\n",
            "04/23/2020 18:21:45 - INFO - utils_squad -   tokens: [CLS] what areas did beyonce compete in when she was growing up ? [SEP] beyonce gi ##selle knowles - carter ( / bi ##ː ##ˈ ##j ##ɒ ##nse ##ɪ / bee - yo ##n - say ) ( born september 4 , 1981 ) is an american singer , songwriter , record producer and actress . born and raised in houston , texas , she performed in various singing and dancing competitions as a child , and rose to fame in the late 1990s as lead singer of r & b girl - group destiny ' s child . managed by her father , mathew knowles , the group became one of the world ' s best - selling girl groups of all time . their hiatus saw the release of beyonce ' s debut album , dangerously in love ( 2003 ) , which established her as a solo artist worldwide , earned five grammy awards and featured the billboard hot 100 number - one singles \" crazy in love \" and \" baby boy \" . [SEP]\n",
            "04/23/2020 18:21:45 - INFO - utils_squad -   token_to_orig_map: 14:0 15:1 16:1 17:2 18:2 19:2 20:3 21:3 22:3 23:3 24:3 25:3 26:3 27:3 28:3 29:3 30:4 31:4 32:4 33:4 34:4 35:4 36:4 37:5 38:5 39:6 40:7 41:7 42:8 43:8 44:9 45:10 46:11 47:12 48:12 49:13 50:13 51:14 52:15 53:16 54:17 55:17 56:18 57:19 58:20 59:21 60:22 61:22 62:23 63:23 64:24 65:25 66:26 67:27 68:28 69:29 70:30 71:31 72:32 73:33 74:34 75:34 76:35 77:36 78:37 79:38 80:39 81:40 82:41 83:42 84:43 85:44 86:45 87:46 88:47 89:47 90:47 91:48 92:48 93:48 94:49 95:49 96:49 97:50 98:50 99:51 100:52 101:53 102:54 103:54 104:55 105:56 106:56 107:57 108:58 109:59 110:60 111:61 112:62 113:63 114:63 115:63 116:64 117:64 118:64 119:65 120:66 121:67 122:68 123:69 124:69 125:70 126:71 127:72 128:73 129:74 130:75 131:76 132:76 133:76 134:77 135:78 136:78 137:79 138:80 139:81 140:82 141:82 142:82 143:82 144:83 145:84 146:85 147:86 148:87 149:88 150:89 151:90 152:90 153:91 154:92 155:93 156:94 157:95 158:96 159:97 160:98 161:99 162:100 163:101 164:101 165:101 166:102 167:103 168:103 169:104 170:105 171:105 172:106 173:107 174:107 175:108 176:108 177:108\n",
            "04/23/2020 18:21:45 - INFO - utils_squad -   token_is_max_context: 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True\n",
            "04/23/2020 18:21:45 - INFO - utils_squad -   input_ids: 101 2054 2752 2106 20773 5566 1999 2043 2016 2001 3652 2039 1029 102 20773 21025 19358 22815 1011 5708 1006 1013 12170 23432 29715 3501 29678 12325 29685 1013 10506 1011 10930 2078 1011 2360 1007 1006 2141 2244 1018 1010 3261 1007 2003 2019 2137 3220 1010 6009 1010 2501 3135 1998 3883 1012 2141 1998 2992 1999 5395 1010 3146 1010 2016 2864 1999 2536 4823 1998 5613 6479 2004 1037 2775 1010 1998 3123 2000 4476 1999 1996 2397 4134 2004 2599 3220 1997 1054 1004 1038 2611 1011 2177 10461 1005 1055 2775 1012 3266 2011 2014 2269 1010 25436 22815 1010 1996 2177 2150 2028 1997 1996 2088 1005 1055 2190 1011 4855 2611 2967 1997 2035 2051 1012 2037 14221 2387 1996 2713 1997 20773 1005 1055 2834 2201 1010 20754 1999 2293 1006 2494 1007 1010 2029 2511 2014 2004 1037 3948 3063 4969 1010 3687 2274 8922 2982 1998 2956 1996 4908 2980 2531 2193 1011 2028 3895 1000 4689 1999 2293 1000 1998 1000 3336 2879 1000 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:45 - INFO - utils_squad -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:45 - INFO - utils_squad -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:45 - INFO - utils_squad -   start_position: 68\n",
            "04/23/2020 18:21:45 - INFO - utils_squad -   end_position: 70\n",
            "04/23/2020 18:21:45 - INFO - utils_squad -   answer: singing and dancing\n",
            "04/23/2020 18:21:45 - INFO - utils_squad -   *** Example ***\n",
            "04/23/2020 18:21:45 - INFO - utils_squad -   unique_id: 1000000002\n",
            "04/23/2020 18:21:45 - INFO - utils_squad -   example_index: 2\n",
            "04/23/2020 18:21:45 - INFO - utils_squad -   doc_span_index: 0\n",
            "04/23/2020 18:21:45 - INFO - utils_squad -   tokens: [CLS] when did beyonce leave destiny ' s child and become a solo singer ? [SEP] beyonce gi ##selle knowles - carter ( / bi ##ː ##ˈ ##j ##ɒ ##nse ##ɪ / bee - yo ##n - say ) ( born september 4 , 1981 ) is an american singer , songwriter , record producer and actress . born and raised in houston , texas , she performed in various singing and dancing competitions as a child , and rose to fame in the late 1990s as lead singer of r & b girl - group destiny ' s child . managed by her father , mathew knowles , the group became one of the world ' s best - selling girl groups of all time . their hiatus saw the release of beyonce ' s debut album , dangerously in love ( 2003 ) , which established her as a solo artist worldwide , earned five grammy awards and featured the billboard hot 100 number - one singles \" crazy in love \" and \" baby boy \" . [SEP]\n",
            "04/23/2020 18:21:45 - INFO - utils_squad -   token_to_orig_map: 16:0 17:1 18:1 19:2 20:2 21:2 22:3 23:3 24:3 25:3 26:3 27:3 28:3 29:3 30:3 31:3 32:4 33:4 34:4 35:4 36:4 37:4 38:4 39:5 40:5 41:6 42:7 43:7 44:8 45:8 46:9 47:10 48:11 49:12 50:12 51:13 52:13 53:14 54:15 55:16 56:17 57:17 58:18 59:19 60:20 61:21 62:22 63:22 64:23 65:23 66:24 67:25 68:26 69:27 70:28 71:29 72:30 73:31 74:32 75:33 76:34 77:34 78:35 79:36 80:37 81:38 82:39 83:40 84:41 85:42 86:43 87:44 88:45 89:46 90:47 91:47 92:47 93:48 94:48 95:48 96:49 97:49 98:49 99:50 100:50 101:51 102:52 103:53 104:54 105:54 106:55 107:56 108:56 109:57 110:58 111:59 112:60 113:61 114:62 115:63 116:63 117:63 118:64 119:64 120:64 121:65 122:66 123:67 124:68 125:69 126:69 127:70 128:71 129:72 130:73 131:74 132:75 133:76 134:76 135:76 136:77 137:78 138:78 139:79 140:80 141:81 142:82 143:82 144:82 145:82 146:83 147:84 148:85 149:86 150:87 151:88 152:89 153:90 154:90 155:91 156:92 157:93 158:94 159:95 160:96 161:97 162:98 163:99 164:100 165:101 166:101 167:101 168:102 169:103 170:103 171:104 172:105 173:105 174:106 175:107 176:107 177:108 178:108 179:108\n",
            "04/23/2020 18:21:45 - INFO - utils_squad -   token_is_max_context: 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True\n",
            "04/23/2020 18:21:45 - INFO - utils_squad -   input_ids: 101 2043 2106 20773 2681 10461 1005 1055 2775 1998 2468 1037 3948 3220 1029 102 20773 21025 19358 22815 1011 5708 1006 1013 12170 23432 29715 3501 29678 12325 29685 1013 10506 1011 10930 2078 1011 2360 1007 1006 2141 2244 1018 1010 3261 1007 2003 2019 2137 3220 1010 6009 1010 2501 3135 1998 3883 1012 2141 1998 2992 1999 5395 1010 3146 1010 2016 2864 1999 2536 4823 1998 5613 6479 2004 1037 2775 1010 1998 3123 2000 4476 1999 1996 2397 4134 2004 2599 3220 1997 1054 1004 1038 2611 1011 2177 10461 1005 1055 2775 1012 3266 2011 2014 2269 1010 25436 22815 1010 1996 2177 2150 2028 1997 1996 2088 1005 1055 2190 1011 4855 2611 2967 1997 2035 2051 1012 2037 14221 2387 1996 2713 1997 20773 1005 1055 2834 2201 1010 20754 1999 2293 1006 2494 1007 1010 2029 2511 2014 2004 1037 3948 3063 4969 1010 3687 2274 8922 2982 1998 2956 1996 4908 2980 2531 2193 1011 2028 3895 1000 4689 1999 2293 1000 1998 1000 3336 2879 1000 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:45 - INFO - utils_squad -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:45 - INFO - utils_squad -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:45 - INFO - utils_squad -   start_position: 143\n",
            "04/23/2020 18:21:45 - INFO - utils_squad -   end_position: 143\n",
            "04/23/2020 18:21:45 - INFO - utils_squad -   answer: 2003\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   *** Example ***\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   unique_id: 1000000003\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   example_index: 3\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   doc_span_index: 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   tokens: [CLS] in what city and state did beyonce grow up ? [SEP] beyonce gi ##selle knowles - carter ( / bi ##ː ##ˈ ##j ##ɒ ##nse ##ɪ / bee - yo ##n - say ) ( born september 4 , 1981 ) is an american singer , songwriter , record producer and actress . born and raised in houston , texas , she performed in various singing and dancing competitions as a child , and rose to fame in the late 1990s as lead singer of r & b girl - group destiny ' s child . managed by her father , mathew knowles , the group became one of the world ' s best - selling girl groups of all time . their hiatus saw the release of beyonce ' s debut album , dangerously in love ( 2003 ) , which established her as a solo artist worldwide , earned five grammy awards and featured the billboard hot 100 number - one singles \" crazy in love \" and \" baby boy \" . [SEP]\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   token_to_orig_map: 12:0 13:1 14:1 15:2 16:2 17:2 18:3 19:3 20:3 21:3 22:3 23:3 24:3 25:3 26:3 27:3 28:4 29:4 30:4 31:4 32:4 33:4 34:4 35:5 36:5 37:6 38:7 39:7 40:8 41:8 42:9 43:10 44:11 45:12 46:12 47:13 48:13 49:14 50:15 51:16 52:17 53:17 54:18 55:19 56:20 57:21 58:22 59:22 60:23 61:23 62:24 63:25 64:26 65:27 66:28 67:29 68:30 69:31 70:32 71:33 72:34 73:34 74:35 75:36 76:37 77:38 78:39 79:40 80:41 81:42 82:43 83:44 84:45 85:46 86:47 87:47 88:47 89:48 90:48 91:48 92:49 93:49 94:49 95:50 96:50 97:51 98:52 99:53 100:54 101:54 102:55 103:56 104:56 105:57 106:58 107:59 108:60 109:61 110:62 111:63 112:63 113:63 114:64 115:64 116:64 117:65 118:66 119:67 120:68 121:69 122:69 123:70 124:71 125:72 126:73 127:74 128:75 129:76 130:76 131:76 132:77 133:78 134:78 135:79 136:80 137:81 138:82 139:82 140:82 141:82 142:83 143:84 144:85 145:86 146:87 147:88 148:89 149:90 150:90 151:91 152:92 153:93 154:94 155:95 156:96 157:97 158:98 159:99 160:100 161:101 162:101 163:101 164:102 165:103 166:103 167:104 168:105 169:105 170:106 171:107 172:107 173:108 174:108 175:108\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   token_is_max_context: 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   input_ids: 101 1999 2054 2103 1998 2110 2106 20773 4982 2039 1029 102 20773 21025 19358 22815 1011 5708 1006 1013 12170 23432 29715 3501 29678 12325 29685 1013 10506 1011 10930 2078 1011 2360 1007 1006 2141 2244 1018 1010 3261 1007 2003 2019 2137 3220 1010 6009 1010 2501 3135 1998 3883 1012 2141 1998 2992 1999 5395 1010 3146 1010 2016 2864 1999 2536 4823 1998 5613 6479 2004 1037 2775 1010 1998 3123 2000 4476 1999 1996 2397 4134 2004 2599 3220 1997 1054 1004 1038 2611 1011 2177 10461 1005 1055 2775 1012 3266 2011 2014 2269 1010 25436 22815 1010 1996 2177 2150 2028 1997 1996 2088 1005 1055 2190 1011 4855 2611 2967 1997 2035 2051 1012 2037 14221 2387 1996 2713 1997 20773 1005 1055 2834 2201 1010 20754 1999 2293 1006 2494 1007 1010 2029 2511 2014 2004 1037 3948 3063 4969 1010 3687 2274 8922 2982 1998 2956 1996 4908 2980 2531 2193 1011 2028 3895 1000 4689 1999 2293 1000 1998 1000 3336 2879 1000 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   start_position: 58\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   end_position: 60\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   answer: houston , texas\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   *** Example ***\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   unique_id: 1000000004\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   example_index: 4\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   doc_span_index: 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   tokens: [CLS] in which decade did beyonce become famous ? [SEP] beyonce gi ##selle knowles - carter ( / bi ##ː ##ˈ ##j ##ɒ ##nse ##ɪ / bee - yo ##n - say ) ( born september 4 , 1981 ) is an american singer , songwriter , record producer and actress . born and raised in houston , texas , she performed in various singing and dancing competitions as a child , and rose to fame in the late 1990s as lead singer of r & b girl - group destiny ' s child . managed by her father , mathew knowles , the group became one of the world ' s best - selling girl groups of all time . their hiatus saw the release of beyonce ' s debut album , dangerously in love ( 2003 ) , which established her as a solo artist worldwide , earned five grammy awards and featured the billboard hot 100 number - one singles \" crazy in love \" and \" baby boy \" . [SEP]\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   token_to_orig_map: 10:0 11:1 12:1 13:2 14:2 15:2 16:3 17:3 18:3 19:3 20:3 21:3 22:3 23:3 24:3 25:3 26:4 27:4 28:4 29:4 30:4 31:4 32:4 33:5 34:5 35:6 36:7 37:7 38:8 39:8 40:9 41:10 42:11 43:12 44:12 45:13 46:13 47:14 48:15 49:16 50:17 51:17 52:18 53:19 54:20 55:21 56:22 57:22 58:23 59:23 60:24 61:25 62:26 63:27 64:28 65:29 66:30 67:31 68:32 69:33 70:34 71:34 72:35 73:36 74:37 75:38 76:39 77:40 78:41 79:42 80:43 81:44 82:45 83:46 84:47 85:47 86:47 87:48 88:48 89:48 90:49 91:49 92:49 93:50 94:50 95:51 96:52 97:53 98:54 99:54 100:55 101:56 102:56 103:57 104:58 105:59 106:60 107:61 108:62 109:63 110:63 111:63 112:64 113:64 114:64 115:65 116:66 117:67 118:68 119:69 120:69 121:70 122:71 123:72 124:73 125:74 126:75 127:76 128:76 129:76 130:77 131:78 132:78 133:79 134:80 135:81 136:82 137:82 138:82 139:82 140:83 141:84 142:85 143:86 144:87 145:88 146:89 147:90 148:90 149:91 150:92 151:93 152:94 153:95 154:96 155:97 156:98 157:99 158:100 159:101 160:101 161:101 162:102 163:103 164:103 165:104 166:105 167:105 168:106 169:107 170:107 171:108 172:108 173:108\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   token_is_max_context: 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   input_ids: 101 1999 2029 5476 2106 20773 2468 3297 1029 102 20773 21025 19358 22815 1011 5708 1006 1013 12170 23432 29715 3501 29678 12325 29685 1013 10506 1011 10930 2078 1011 2360 1007 1006 2141 2244 1018 1010 3261 1007 2003 2019 2137 3220 1010 6009 1010 2501 3135 1998 3883 1012 2141 1998 2992 1999 5395 1010 3146 1010 2016 2864 1999 2536 4823 1998 5613 6479 2004 1037 2775 1010 1998 3123 2000 4476 1999 1996 2397 4134 2004 2599 3220 1997 1054 1004 1038 2611 1011 2177 10461 1005 1055 2775 1012 3266 2011 2014 2269 1010 25436 22815 1010 1996 2177 2150 2028 1997 1996 2088 1005 1055 2190 1011 4855 2611 2967 1997 2035 2051 1012 2037 14221 2387 1996 2713 1997 20773 1005 1055 2834 2201 1010 20754 1999 2293 1006 2494 1007 1010 2029 2511 2014 2004 1037 3948 3063 4969 1010 3687 2274 8922 2982 1998 2956 1996 4908 2980 2531 2193 1011 2028 3895 1000 4689 1999 2293 1000 1998 1000 3336 2879 1000 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   start_position: 78\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   end_position: 79\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   answer: late 1990s\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   *** Example ***\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   unique_id: 1000000005\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   example_index: 5\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   doc_span_index: 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   tokens: [CLS] in what r & b group was she the lead singer ? [SEP] beyonce gi ##selle knowles - carter ( / bi ##ː ##ˈ ##j ##ɒ ##nse ##ɪ / bee - yo ##n - say ) ( born september 4 , 1981 ) is an american singer , songwriter , record producer and actress . born and raised in houston , texas , she performed in various singing and dancing competitions as a child , and rose to fame in the late 1990s as lead singer of r & b girl - group destiny ' s child . managed by her father , mathew knowles , the group became one of the world ' s best - selling girl groups of all time . their hiatus saw the release of beyonce ' s debut album , dangerously in love ( 2003 ) , which established her as a solo artist worldwide , earned five grammy awards and featured the billboard hot 100 number - one singles \" crazy in love \" and \" baby boy \" . [SEP]\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   token_to_orig_map: 14:0 15:1 16:1 17:2 18:2 19:2 20:3 21:3 22:3 23:3 24:3 25:3 26:3 27:3 28:3 29:3 30:4 31:4 32:4 33:4 34:4 35:4 36:4 37:5 38:5 39:6 40:7 41:7 42:8 43:8 44:9 45:10 46:11 47:12 48:12 49:13 50:13 51:14 52:15 53:16 54:17 55:17 56:18 57:19 58:20 59:21 60:22 61:22 62:23 63:23 64:24 65:25 66:26 67:27 68:28 69:29 70:30 71:31 72:32 73:33 74:34 75:34 76:35 77:36 78:37 79:38 80:39 81:40 82:41 83:42 84:43 85:44 86:45 87:46 88:47 89:47 90:47 91:48 92:48 93:48 94:49 95:49 96:49 97:50 98:50 99:51 100:52 101:53 102:54 103:54 104:55 105:56 106:56 107:57 108:58 109:59 110:60 111:61 112:62 113:63 114:63 115:63 116:64 117:64 118:64 119:65 120:66 121:67 122:68 123:69 124:69 125:70 126:71 127:72 128:73 129:74 130:75 131:76 132:76 133:76 134:77 135:78 136:78 137:79 138:80 139:81 140:82 141:82 142:82 143:82 144:83 145:84 146:85 147:86 148:87 149:88 150:89 151:90 152:90 153:91 154:92 155:93 156:94 157:95 158:96 159:97 160:98 161:99 162:100 163:101 164:101 165:101 166:102 167:103 168:103 169:104 170:105 171:105 172:106 173:107 174:107 175:108 176:108 177:108\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   token_is_max_context: 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   input_ids: 101 1999 2054 1054 1004 1038 2177 2001 2016 1996 2599 3220 1029 102 20773 21025 19358 22815 1011 5708 1006 1013 12170 23432 29715 3501 29678 12325 29685 1013 10506 1011 10930 2078 1011 2360 1007 1006 2141 2244 1018 1010 3261 1007 2003 2019 2137 3220 1010 6009 1010 2501 3135 1998 3883 1012 2141 1998 2992 1999 5395 1010 3146 1010 2016 2864 1999 2536 4823 1998 5613 6479 2004 1037 2775 1010 1998 3123 2000 4476 1999 1996 2397 4134 2004 2599 3220 1997 1054 1004 1038 2611 1011 2177 10461 1005 1055 2775 1012 3266 2011 2014 2269 1010 25436 22815 1010 1996 2177 2150 2028 1997 1996 2088 1005 1055 2190 1011 4855 2611 2967 1997 2035 2051 1012 2037 14221 2387 1996 2713 1997 20773 1005 1055 2834 2201 1010 20754 1999 2293 1006 2494 1007 1010 2029 2511 2014 2004 1037 3948 3063 4969 1010 3687 2274 8922 2982 1998 2956 1996 4908 2980 2531 2193 1011 2028 3895 1000 4689 1999 2293 1000 1998 1000 3336 2879 1000 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   start_position: 94\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   end_position: 97\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   answer: destiny ' s child\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   *** Example ***\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   unique_id: 1000000006\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   example_index: 6\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   doc_span_index: 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   tokens: [CLS] what album made her a worldwide known artist ? [SEP] beyonce gi ##selle knowles - carter ( / bi ##ː ##ˈ ##j ##ɒ ##nse ##ɪ / bee - yo ##n - say ) ( born september 4 , 1981 ) is an american singer , songwriter , record producer and actress . born and raised in houston , texas , she performed in various singing and dancing competitions as a child , and rose to fame in the late 1990s as lead singer of r & b girl - group destiny ' s child . managed by her father , mathew knowles , the group became one of the world ' s best - selling girl groups of all time . their hiatus saw the release of beyonce ' s debut album , dangerously in love ( 2003 ) , which established her as a solo artist worldwide , earned five grammy awards and featured the billboard hot 100 number - one singles \" crazy in love \" and \" baby boy \" . [SEP]\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   token_to_orig_map: 11:0 12:1 13:1 14:2 15:2 16:2 17:3 18:3 19:3 20:3 21:3 22:3 23:3 24:3 25:3 26:3 27:4 28:4 29:4 30:4 31:4 32:4 33:4 34:5 35:5 36:6 37:7 38:7 39:8 40:8 41:9 42:10 43:11 44:12 45:12 46:13 47:13 48:14 49:15 50:16 51:17 52:17 53:18 54:19 55:20 56:21 57:22 58:22 59:23 60:23 61:24 62:25 63:26 64:27 65:28 66:29 67:30 68:31 69:32 70:33 71:34 72:34 73:35 74:36 75:37 76:38 77:39 78:40 79:41 80:42 81:43 82:44 83:45 84:46 85:47 86:47 87:47 88:48 89:48 90:48 91:49 92:49 93:49 94:50 95:50 96:51 97:52 98:53 99:54 100:54 101:55 102:56 103:56 104:57 105:58 106:59 107:60 108:61 109:62 110:63 111:63 112:63 113:64 114:64 115:64 116:65 117:66 118:67 119:68 120:69 121:69 122:70 123:71 124:72 125:73 126:74 127:75 128:76 129:76 130:76 131:77 132:78 133:78 134:79 135:80 136:81 137:82 138:82 139:82 140:82 141:83 142:84 143:85 144:86 145:87 146:88 147:89 148:90 149:90 150:91 151:92 152:93 153:94 154:95 155:96 156:97 157:98 158:99 159:100 160:101 161:101 162:101 163:102 164:103 165:103 166:104 167:105 168:105 169:106 170:107 171:107 172:108 173:108 174:108\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   token_is_max_context: 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   input_ids: 101 2054 2201 2081 2014 1037 4969 2124 3063 1029 102 20773 21025 19358 22815 1011 5708 1006 1013 12170 23432 29715 3501 29678 12325 29685 1013 10506 1011 10930 2078 1011 2360 1007 1006 2141 2244 1018 1010 3261 1007 2003 2019 2137 3220 1010 6009 1010 2501 3135 1998 3883 1012 2141 1998 2992 1999 5395 1010 3146 1010 2016 2864 1999 2536 4823 1998 5613 6479 2004 1037 2775 1010 1998 3123 2000 4476 1999 1996 2397 4134 2004 2599 3220 1997 1054 1004 1038 2611 1011 2177 10461 1005 1055 2775 1012 3266 2011 2014 2269 1010 25436 22815 1010 1996 2177 2150 2028 1997 1996 2088 1005 1055 2190 1011 4855 2611 2967 1997 2035 2051 1012 2037 14221 2387 1996 2713 1997 20773 1005 1055 2834 2201 1010 20754 1999 2293 1006 2494 1007 1010 2029 2511 2014 2004 1037 3948 3063 4969 1010 3687 2274 8922 2982 1998 2956 1996 4908 2980 2531 2193 1011 2028 3895 1000 4689 1999 2293 1000 1998 1000 3336 2879 1000 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   start_position: 134\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   end_position: 136\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   answer: dangerously in love\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   *** Example ***\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   unique_id: 1000000007\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   example_index: 7\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   doc_span_index: 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   tokens: [CLS] who managed the destiny ' s child group ? [SEP] beyonce gi ##selle knowles - carter ( / bi ##ː ##ˈ ##j ##ɒ ##nse ##ɪ / bee - yo ##n - say ) ( born september 4 , 1981 ) is an american singer , songwriter , record producer and actress . born and raised in houston , texas , she performed in various singing and dancing competitions as a child , and rose to fame in the late 1990s as lead singer of r & b girl - group destiny ' s child . managed by her father , mathew knowles , the group became one of the world ' s best - selling girl groups of all time . their hiatus saw the release of beyonce ' s debut album , dangerously in love ( 2003 ) , which established her as a solo artist worldwide , earned five grammy awards and featured the billboard hot 100 number - one singles \" crazy in love \" and \" baby boy \" . [SEP]\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   token_to_orig_map: 11:0 12:1 13:1 14:2 15:2 16:2 17:3 18:3 19:3 20:3 21:3 22:3 23:3 24:3 25:3 26:3 27:4 28:4 29:4 30:4 31:4 32:4 33:4 34:5 35:5 36:6 37:7 38:7 39:8 40:8 41:9 42:10 43:11 44:12 45:12 46:13 47:13 48:14 49:15 50:16 51:17 52:17 53:18 54:19 55:20 56:21 57:22 58:22 59:23 60:23 61:24 62:25 63:26 64:27 65:28 66:29 67:30 68:31 69:32 70:33 71:34 72:34 73:35 74:36 75:37 76:38 77:39 78:40 79:41 80:42 81:43 82:44 83:45 84:46 85:47 86:47 87:47 88:48 89:48 90:48 91:49 92:49 93:49 94:50 95:50 96:51 97:52 98:53 99:54 100:54 101:55 102:56 103:56 104:57 105:58 106:59 107:60 108:61 109:62 110:63 111:63 112:63 113:64 114:64 115:64 116:65 117:66 118:67 119:68 120:69 121:69 122:70 123:71 124:72 125:73 126:74 127:75 128:76 129:76 130:76 131:77 132:78 133:78 134:79 135:80 136:81 137:82 138:82 139:82 140:82 141:83 142:84 143:85 144:86 145:87 146:88 147:89 148:90 149:90 150:91 151:92 152:93 153:94 154:95 155:96 156:97 157:98 158:99 159:100 160:101 161:101 162:101 163:102 164:103 165:103 166:104 167:105 168:105 169:106 170:107 171:107 172:108 173:108 174:108\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   token_is_max_context: 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   input_ids: 101 2040 3266 1996 10461 1005 1055 2775 2177 1029 102 20773 21025 19358 22815 1011 5708 1006 1013 12170 23432 29715 3501 29678 12325 29685 1013 10506 1011 10930 2078 1011 2360 1007 1006 2141 2244 1018 1010 3261 1007 2003 2019 2137 3220 1010 6009 1010 2501 3135 1998 3883 1012 2141 1998 2992 1999 5395 1010 3146 1010 2016 2864 1999 2536 4823 1998 5613 6479 2004 1037 2775 1010 1998 3123 2000 4476 1999 1996 2397 4134 2004 2599 3220 1997 1054 1004 1038 2611 1011 2177 10461 1005 1055 2775 1012 3266 2011 2014 2269 1010 25436 22815 1010 1996 2177 2150 2028 1997 1996 2088 1005 1055 2190 1011 4855 2611 2967 1997 2035 2051 1012 2037 14221 2387 1996 2713 1997 20773 1005 1055 2834 2201 1010 20754 1999 2293 1006 2494 1007 1010 2029 2511 2014 2004 1037 3948 3063 4969 1010 3687 2274 8922 2982 1998 2956 1996 4908 2980 2531 2193 1011 2028 3895 1000 4689 1999 2293 1000 1998 1000 3336 2879 1000 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   start_position: 101\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   end_position: 102\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   answer: mathew knowles\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   *** Example ***\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   unique_id: 1000000008\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   example_index: 8\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   doc_span_index: 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   tokens: [CLS] when did beyonce rise to fame ? [SEP] beyonce gi ##selle knowles - carter ( / bi ##ː ##ˈ ##j ##ɒ ##nse ##ɪ / bee - yo ##n - say ) ( born september 4 , 1981 ) is an american singer , songwriter , record producer and actress . born and raised in houston , texas , she performed in various singing and dancing competitions as a child , and rose to fame in the late 1990s as lead singer of r & b girl - group destiny ' s child . managed by her father , mathew knowles , the group became one of the world ' s best - selling girl groups of all time . their hiatus saw the release of beyonce ' s debut album , dangerously in love ( 2003 ) , which established her as a solo artist worldwide , earned five grammy awards and featured the billboard hot 100 number - one singles \" crazy in love \" and \" baby boy \" . [SEP]\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   token_to_orig_map: 9:0 10:1 11:1 12:2 13:2 14:2 15:3 16:3 17:3 18:3 19:3 20:3 21:3 22:3 23:3 24:3 25:4 26:4 27:4 28:4 29:4 30:4 31:4 32:5 33:5 34:6 35:7 36:7 37:8 38:8 39:9 40:10 41:11 42:12 43:12 44:13 45:13 46:14 47:15 48:16 49:17 50:17 51:18 52:19 53:20 54:21 55:22 56:22 57:23 58:23 59:24 60:25 61:26 62:27 63:28 64:29 65:30 66:31 67:32 68:33 69:34 70:34 71:35 72:36 73:37 74:38 75:39 76:40 77:41 78:42 79:43 80:44 81:45 82:46 83:47 84:47 85:47 86:48 87:48 88:48 89:49 90:49 91:49 92:50 93:50 94:51 95:52 96:53 97:54 98:54 99:55 100:56 101:56 102:57 103:58 104:59 105:60 106:61 107:62 108:63 109:63 110:63 111:64 112:64 113:64 114:65 115:66 116:67 117:68 118:69 119:69 120:70 121:71 122:72 123:73 124:74 125:75 126:76 127:76 128:76 129:77 130:78 131:78 132:79 133:80 134:81 135:82 136:82 137:82 138:82 139:83 140:84 141:85 142:86 143:87 144:88 145:89 146:90 147:90 148:91 149:92 150:93 151:94 152:95 153:96 154:97 155:98 156:99 157:100 158:101 159:101 160:101 161:102 162:103 163:103 164:104 165:105 166:105 167:106 168:107 169:107 170:108 171:108 172:108\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   input_ids: 101 2043 2106 20773 4125 2000 4476 1029 102 20773 21025 19358 22815 1011 5708 1006 1013 12170 23432 29715 3501 29678 12325 29685 1013 10506 1011 10930 2078 1011 2360 1007 1006 2141 2244 1018 1010 3261 1007 2003 2019 2137 3220 1010 6009 1010 2501 3135 1998 3883 1012 2141 1998 2992 1999 5395 1010 3146 1010 2016 2864 1999 2536 4823 1998 5613 6479 2004 1037 2775 1010 1998 3123 2000 4476 1999 1996 2397 4134 2004 2599 3220 1997 1054 1004 1038 2611 1011 2177 10461 1005 1055 2775 1012 3266 2011 2014 2269 1010 25436 22815 1010 1996 2177 2150 2028 1997 1996 2088 1005 1055 2190 1011 4855 2611 2967 1997 2035 2051 1012 2037 14221 2387 1996 2713 1997 20773 1005 1055 2834 2201 1010 20754 1999 2293 1006 2494 1007 1010 2029 2511 2014 2004 1037 3948 3063 4969 1010 3687 2274 8922 2982 1998 2956 1996 4908 2980 2531 2193 1011 2028 3895 1000 4689 1999 2293 1000 1998 1000 3336 2879 1000 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   start_position: 77\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   end_position: 78\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   answer: late 1990s\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   *** Example ***\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   unique_id: 1000000009\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   example_index: 9\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   doc_span_index: 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   tokens: [CLS] what role did beyonce have in destiny ' s child ? [SEP] beyonce gi ##selle knowles - carter ( / bi ##ː ##ˈ ##j ##ɒ ##nse ##ɪ / bee - yo ##n - say ) ( born september 4 , 1981 ) is an american singer , songwriter , record producer and actress . born and raised in houston , texas , she performed in various singing and dancing competitions as a child , and rose to fame in the late 1990s as lead singer of r & b girl - group destiny ' s child . managed by her father , mathew knowles , the group became one of the world ' s best - selling girl groups of all time . their hiatus saw the release of beyonce ' s debut album , dangerously in love ( 2003 ) , which established her as a solo artist worldwide , earned five grammy awards and featured the billboard hot 100 number - one singles \" crazy in love \" and \" baby boy \" . [SEP]\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   token_to_orig_map: 13:0 14:1 15:1 16:2 17:2 18:2 19:3 20:3 21:3 22:3 23:3 24:3 25:3 26:3 27:3 28:3 29:4 30:4 31:4 32:4 33:4 34:4 35:4 36:5 37:5 38:6 39:7 40:7 41:8 42:8 43:9 44:10 45:11 46:12 47:12 48:13 49:13 50:14 51:15 52:16 53:17 54:17 55:18 56:19 57:20 58:21 59:22 60:22 61:23 62:23 63:24 64:25 65:26 66:27 67:28 68:29 69:30 70:31 71:32 72:33 73:34 74:34 75:35 76:36 77:37 78:38 79:39 80:40 81:41 82:42 83:43 84:44 85:45 86:46 87:47 88:47 89:47 90:48 91:48 92:48 93:49 94:49 95:49 96:50 97:50 98:51 99:52 100:53 101:54 102:54 103:55 104:56 105:56 106:57 107:58 108:59 109:60 110:61 111:62 112:63 113:63 114:63 115:64 116:64 117:64 118:65 119:66 120:67 121:68 122:69 123:69 124:70 125:71 126:72 127:73 128:74 129:75 130:76 131:76 132:76 133:77 134:78 135:78 136:79 137:80 138:81 139:82 140:82 141:82 142:82 143:83 144:84 145:85 146:86 147:87 148:88 149:89 150:90 151:90 152:91 153:92 154:93 155:94 156:95 157:96 158:97 159:98 160:99 161:100 162:101 163:101 164:101 165:102 166:103 167:103 168:104 169:105 170:105 171:106 172:107 173:107 174:108 175:108 176:108\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   token_is_max_context: 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   input_ids: 101 2054 2535 2106 20773 2031 1999 10461 1005 1055 2775 1029 102 20773 21025 19358 22815 1011 5708 1006 1013 12170 23432 29715 3501 29678 12325 29685 1013 10506 1011 10930 2078 1011 2360 1007 1006 2141 2244 1018 1010 3261 1007 2003 2019 2137 3220 1010 6009 1010 2501 3135 1998 3883 1012 2141 1998 2992 1999 5395 1010 3146 1010 2016 2864 1999 2536 4823 1998 5613 6479 2004 1037 2775 1010 1998 3123 2000 4476 1999 1996 2397 4134 2004 2599 3220 1997 1054 1004 1038 2611 1011 2177 10461 1005 1055 2775 1012 3266 2011 2014 2269 1010 25436 22815 1010 1996 2177 2150 2028 1997 1996 2088 1005 1055 2190 1011 4855 2611 2967 1997 2035 2051 1012 2037 14221 2387 1996 2713 1997 20773 1005 1055 2834 2201 1010 20754 1999 2293 1006 2494 1007 1010 2029 2511 2014 2004 1037 3948 3063 4969 1010 3687 2274 8922 2982 1998 2956 1996 4908 2980 2531 2193 1011 2028 3895 1000 4689 1999 2293 1000 1998 1000 3336 2879 1000 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   start_position: 84\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   end_position: 85\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   answer: lead singer\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   *** Example ***\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   unique_id: 1000000010\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   example_index: 10\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   doc_span_index: 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   tokens: [CLS] what was the first album beyonce released as a solo artist ? [SEP] beyonce gi ##selle knowles - carter ( / bi ##ː ##ˈ ##j ##ɒ ##nse ##ɪ / bee - yo ##n - say ) ( born september 4 , 1981 ) is an american singer , songwriter , record producer and actress . born and raised in houston , texas , she performed in various singing and dancing competitions as a child , and rose to fame in the late 1990s as lead singer of r & b girl - group destiny ' s child . managed by her father , mathew knowles , the group became one of the world ' s best - selling girl groups of all time . their hiatus saw the release of beyonce ' s debut album , dangerously in love ( 2003 ) , which established her as a solo artist worldwide , earned five grammy awards and featured the billboard hot 100 number - one singles \" crazy in love \" and \" baby boy \" . [SEP]\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   token_to_orig_map: 14:0 15:1 16:1 17:2 18:2 19:2 20:3 21:3 22:3 23:3 24:3 25:3 26:3 27:3 28:3 29:3 30:4 31:4 32:4 33:4 34:4 35:4 36:4 37:5 38:5 39:6 40:7 41:7 42:8 43:8 44:9 45:10 46:11 47:12 48:12 49:13 50:13 51:14 52:15 53:16 54:17 55:17 56:18 57:19 58:20 59:21 60:22 61:22 62:23 63:23 64:24 65:25 66:26 67:27 68:28 69:29 70:30 71:31 72:32 73:33 74:34 75:34 76:35 77:36 78:37 79:38 80:39 81:40 82:41 83:42 84:43 85:44 86:45 87:46 88:47 89:47 90:47 91:48 92:48 93:48 94:49 95:49 96:49 97:50 98:50 99:51 100:52 101:53 102:54 103:54 104:55 105:56 106:56 107:57 108:58 109:59 110:60 111:61 112:62 113:63 114:63 115:63 116:64 117:64 118:64 119:65 120:66 121:67 122:68 123:69 124:69 125:70 126:71 127:72 128:73 129:74 130:75 131:76 132:76 133:76 134:77 135:78 136:78 137:79 138:80 139:81 140:82 141:82 142:82 143:82 144:83 145:84 146:85 147:86 148:87 149:88 150:89 151:90 152:90 153:91 154:92 155:93 156:94 157:95 158:96 159:97 160:98 161:99 162:100 163:101 164:101 165:101 166:102 167:103 168:103 169:104 170:105 171:105 172:106 173:107 174:107 175:108 176:108 177:108\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   token_is_max_context: 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   input_ids: 101 2054 2001 1996 2034 2201 20773 2207 2004 1037 3948 3063 1029 102 20773 21025 19358 22815 1011 5708 1006 1013 12170 23432 29715 3501 29678 12325 29685 1013 10506 1011 10930 2078 1011 2360 1007 1006 2141 2244 1018 1010 3261 1007 2003 2019 2137 3220 1010 6009 1010 2501 3135 1998 3883 1012 2141 1998 2992 1999 5395 1010 3146 1010 2016 2864 1999 2536 4823 1998 5613 6479 2004 1037 2775 1010 1998 3123 2000 4476 1999 1996 2397 4134 2004 2599 3220 1997 1054 1004 1038 2611 1011 2177 10461 1005 1055 2775 1012 3266 2011 2014 2269 1010 25436 22815 1010 1996 2177 2150 2028 1997 1996 2088 1005 1055 2190 1011 4855 2611 2967 1997 2035 2051 1012 2037 14221 2387 1996 2713 1997 20773 1005 1055 2834 2201 1010 20754 1999 2293 1006 2494 1007 1010 2029 2511 2014 2004 1037 3948 3063 4969 1010 3687 2274 8922 2982 1998 2956 1996 4908 2980 2531 2193 1011 2028 3895 1000 4689 1999 2293 1000 1998 1000 3336 2879 1000 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   start_position: 137\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   end_position: 139\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   answer: dangerously in love\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   *** Example ***\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   unique_id: 1000000011\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   example_index: 11\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   doc_span_index: 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   tokens: [CLS] when did beyonce release dangerously in love ? [SEP] beyonce gi ##selle knowles - carter ( / bi ##ː ##ˈ ##j ##ɒ ##nse ##ɪ / bee - yo ##n - say ) ( born september 4 , 1981 ) is an american singer , songwriter , record producer and actress . born and raised in houston , texas , she performed in various singing and dancing competitions as a child , and rose to fame in the late 1990s as lead singer of r & b girl - group destiny ' s child . managed by her father , mathew knowles , the group became one of the world ' s best - selling girl groups of all time . their hiatus saw the release of beyonce ' s debut album , dangerously in love ( 2003 ) , which established her as a solo artist worldwide , earned five grammy awards and featured the billboard hot 100 number - one singles \" crazy in love \" and \" baby boy \" . [SEP]\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   token_to_orig_map: 10:0 11:1 12:1 13:2 14:2 15:2 16:3 17:3 18:3 19:3 20:3 21:3 22:3 23:3 24:3 25:3 26:4 27:4 28:4 29:4 30:4 31:4 32:4 33:5 34:5 35:6 36:7 37:7 38:8 39:8 40:9 41:10 42:11 43:12 44:12 45:13 46:13 47:14 48:15 49:16 50:17 51:17 52:18 53:19 54:20 55:21 56:22 57:22 58:23 59:23 60:24 61:25 62:26 63:27 64:28 65:29 66:30 67:31 68:32 69:33 70:34 71:34 72:35 73:36 74:37 75:38 76:39 77:40 78:41 79:42 80:43 81:44 82:45 83:46 84:47 85:47 86:47 87:48 88:48 89:48 90:49 91:49 92:49 93:50 94:50 95:51 96:52 97:53 98:54 99:54 100:55 101:56 102:56 103:57 104:58 105:59 106:60 107:61 108:62 109:63 110:63 111:63 112:64 113:64 114:64 115:65 116:66 117:67 118:68 119:69 120:69 121:70 122:71 123:72 124:73 125:74 126:75 127:76 128:76 129:76 130:77 131:78 132:78 133:79 134:80 135:81 136:82 137:82 138:82 139:82 140:83 141:84 142:85 143:86 144:87 145:88 146:89 147:90 148:90 149:91 150:92 151:93 152:94 153:95 154:96 155:97 156:98 157:99 158:100 159:101 160:101 161:101 162:102 163:103 164:103 165:104 166:105 167:105 168:106 169:107 170:107 171:108 172:108 173:108\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   token_is_max_context: 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   input_ids: 101 2043 2106 20773 2713 20754 1999 2293 1029 102 20773 21025 19358 22815 1011 5708 1006 1013 12170 23432 29715 3501 29678 12325 29685 1013 10506 1011 10930 2078 1011 2360 1007 1006 2141 2244 1018 1010 3261 1007 2003 2019 2137 3220 1010 6009 1010 2501 3135 1998 3883 1012 2141 1998 2992 1999 5395 1010 3146 1010 2016 2864 1999 2536 4823 1998 5613 6479 2004 1037 2775 1010 1998 3123 2000 4476 1999 1996 2397 4134 2004 2599 3220 1997 1054 1004 1038 2611 1011 2177 10461 1005 1055 2775 1012 3266 2011 2014 2269 1010 25436 22815 1010 1996 2177 2150 2028 1997 1996 2088 1005 1055 2190 1011 4855 2611 2967 1997 2035 2051 1012 2037 14221 2387 1996 2713 1997 20773 1005 1055 2834 2201 1010 20754 1999 2293 1006 2494 1007 1010 2029 2511 2014 2004 1037 3948 3063 4969 1010 3687 2274 8922 2982 1998 2956 1996 4908 2980 2531 2193 1011 2028 3895 1000 4689 1999 2293 1000 1998 1000 3336 2879 1000 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   start_position: 137\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   end_position: 137\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   answer: 2003\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   *** Example ***\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   unique_id: 1000000012\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   example_index: 12\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   doc_span_index: 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   tokens: [CLS] how many grammy awards did beyonce win for her first solo album ? [SEP] beyonce gi ##selle knowles - carter ( / bi ##ː ##ˈ ##j ##ɒ ##nse ##ɪ / bee - yo ##n - say ) ( born september 4 , 1981 ) is an american singer , songwriter , record producer and actress . born and raised in houston , texas , she performed in various singing and dancing competitions as a child , and rose to fame in the late 1990s as lead singer of r & b girl - group destiny ' s child . managed by her father , mathew knowles , the group became one of the world ' s best - selling girl groups of all time . their hiatus saw the release of beyonce ' s debut album , dangerously in love ( 2003 ) , which established her as a solo artist worldwide , earned five grammy awards and featured the billboard hot 100 number - one singles \" crazy in love \" and \" baby boy \" . [SEP]\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   token_to_orig_map: 15:0 16:1 17:1 18:2 19:2 20:2 21:3 22:3 23:3 24:3 25:3 26:3 27:3 28:3 29:3 30:3 31:4 32:4 33:4 34:4 35:4 36:4 37:4 38:5 39:5 40:6 41:7 42:7 43:8 44:8 45:9 46:10 47:11 48:12 49:12 50:13 51:13 52:14 53:15 54:16 55:17 56:17 57:18 58:19 59:20 60:21 61:22 62:22 63:23 64:23 65:24 66:25 67:26 68:27 69:28 70:29 71:30 72:31 73:32 74:33 75:34 76:34 77:35 78:36 79:37 80:38 81:39 82:40 83:41 84:42 85:43 86:44 87:45 88:46 89:47 90:47 91:47 92:48 93:48 94:48 95:49 96:49 97:49 98:50 99:50 100:51 101:52 102:53 103:54 104:54 105:55 106:56 107:56 108:57 109:58 110:59 111:60 112:61 113:62 114:63 115:63 116:63 117:64 118:64 119:64 120:65 121:66 122:67 123:68 124:69 125:69 126:70 127:71 128:72 129:73 130:74 131:75 132:76 133:76 134:76 135:77 136:78 137:78 138:79 139:80 140:81 141:82 142:82 143:82 144:82 145:83 146:84 147:85 148:86 149:87 150:88 151:89 152:90 153:90 154:91 155:92 156:93 157:94 158:95 159:96 160:97 161:98 162:99 163:100 164:101 165:101 166:101 167:102 168:103 169:103 170:104 171:105 172:105 173:106 174:107 175:107 176:108 177:108 178:108\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   token_is_max_context: 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   input_ids: 101 2129 2116 8922 2982 2106 20773 2663 2005 2014 2034 3948 2201 1029 102 20773 21025 19358 22815 1011 5708 1006 1013 12170 23432 29715 3501 29678 12325 29685 1013 10506 1011 10930 2078 1011 2360 1007 1006 2141 2244 1018 1010 3261 1007 2003 2019 2137 3220 1010 6009 1010 2501 3135 1998 3883 1012 2141 1998 2992 1999 5395 1010 3146 1010 2016 2864 1999 2536 4823 1998 5613 6479 2004 1037 2775 1010 1998 3123 2000 4476 1999 1996 2397 4134 2004 2599 3220 1997 1054 1004 1038 2611 1011 2177 10461 1005 1055 2775 1012 3266 2011 2014 2269 1010 25436 22815 1010 1996 2177 2150 2028 1997 1996 2088 1005 1055 2190 1011 4855 2611 2967 1997 2035 2051 1012 2037 14221 2387 1996 2713 1997 20773 1005 1055 2834 2201 1010 20754 1999 2293 1006 2494 1007 1010 2029 2511 2014 2004 1037 3948 3063 4969 1010 3687 2274 8922 2982 1998 2956 1996 4908 2980 2531 2193 1011 2028 3895 1000 4689 1999 2293 1000 1998 1000 3336 2879 1000 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   start_position: 155\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   end_position: 155\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   answer: five\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   *** Example ***\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   unique_id: 1000000013\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   example_index: 13\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   doc_span_index: 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   tokens: [CLS] what was beyonce ' s role in destiny ' s child ? [SEP] beyonce gi ##selle knowles - carter ( / bi ##ː ##ˈ ##j ##ɒ ##nse ##ɪ / bee - yo ##n - say ) ( born september 4 , 1981 ) is an american singer , songwriter , record producer and actress . born and raised in houston , texas , she performed in various singing and dancing competitions as a child , and rose to fame in the late 1990s as lead singer of r & b girl - group destiny ' s child . managed by her father , mathew knowles , the group became one of the world ' s best - selling girl groups of all time . their hiatus saw the release of beyonce ' s debut album , dangerously in love ( 2003 ) , which established her as a solo artist worldwide , earned five grammy awards and featured the billboard hot 100 number - one singles \" crazy in love \" and \" baby boy \" . [SEP]\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   token_to_orig_map: 14:0 15:1 16:1 17:2 18:2 19:2 20:3 21:3 22:3 23:3 24:3 25:3 26:3 27:3 28:3 29:3 30:4 31:4 32:4 33:4 34:4 35:4 36:4 37:5 38:5 39:6 40:7 41:7 42:8 43:8 44:9 45:10 46:11 47:12 48:12 49:13 50:13 51:14 52:15 53:16 54:17 55:17 56:18 57:19 58:20 59:21 60:22 61:22 62:23 63:23 64:24 65:25 66:26 67:27 68:28 69:29 70:30 71:31 72:32 73:33 74:34 75:34 76:35 77:36 78:37 79:38 80:39 81:40 82:41 83:42 84:43 85:44 86:45 87:46 88:47 89:47 90:47 91:48 92:48 93:48 94:49 95:49 96:49 97:50 98:50 99:51 100:52 101:53 102:54 103:54 104:55 105:56 106:56 107:57 108:58 109:59 110:60 111:61 112:62 113:63 114:63 115:63 116:64 117:64 118:64 119:65 120:66 121:67 122:68 123:69 124:69 125:70 126:71 127:72 128:73 129:74 130:75 131:76 132:76 133:76 134:77 135:78 136:78 137:79 138:80 139:81 140:82 141:82 142:82 143:82 144:83 145:84 146:85 147:86 148:87 149:88 150:89 151:90 152:90 153:91 154:92 155:93 156:94 157:95 158:96 159:97 160:98 161:99 162:100 163:101 164:101 165:101 166:102 167:103 168:103 169:104 170:105 171:105 172:106 173:107 174:107 175:108 176:108 177:108\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   token_is_max_context: 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   input_ids: 101 2054 2001 20773 1005 1055 2535 1999 10461 1005 1055 2775 1029 102 20773 21025 19358 22815 1011 5708 1006 1013 12170 23432 29715 3501 29678 12325 29685 1013 10506 1011 10930 2078 1011 2360 1007 1006 2141 2244 1018 1010 3261 1007 2003 2019 2137 3220 1010 6009 1010 2501 3135 1998 3883 1012 2141 1998 2992 1999 5395 1010 3146 1010 2016 2864 1999 2536 4823 1998 5613 6479 2004 1037 2775 1010 1998 3123 2000 4476 1999 1996 2397 4134 2004 2599 3220 1997 1054 1004 1038 2611 1011 2177 10461 1005 1055 2775 1012 3266 2011 2014 2269 1010 25436 22815 1010 1996 2177 2150 2028 1997 1996 2088 1005 1055 2190 1011 4855 2611 2967 1997 2035 2051 1012 2037 14221 2387 1996 2713 1997 20773 1005 1055 2834 2201 1010 20754 1999 2293 1006 2494 1007 1010 2029 2511 2014 2004 1037 3948 3063 4969 1010 3687 2274 8922 2982 1998 2956 1996 4908 2980 2531 2193 1011 2028 3895 1000 4689 1999 2293 1000 1998 1000 3336 2879 1000 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   start_position: 85\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   end_position: 86\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   answer: lead singer\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   *** Example ***\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   unique_id: 1000000014\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   example_index: 14\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   doc_span_index: 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   tokens: [CLS] what was the name of beyonce ' s first solo album ? [SEP] beyonce gi ##selle knowles - carter ( / bi ##ː ##ˈ ##j ##ɒ ##nse ##ɪ / bee - yo ##n - say ) ( born september 4 , 1981 ) is an american singer , songwriter , record producer and actress . born and raised in houston , texas , she performed in various singing and dancing competitions as a child , and rose to fame in the late 1990s as lead singer of r & b girl - group destiny ' s child . managed by her father , mathew knowles , the group became one of the world ' s best - selling girl groups of all time . their hiatus saw the release of beyonce ' s debut album , dangerously in love ( 2003 ) , which established her as a solo artist worldwide , earned five grammy awards and featured the billboard hot 100 number - one singles \" crazy in love \" and \" baby boy \" . [SEP]\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   token_to_orig_map: 14:0 15:1 16:1 17:2 18:2 19:2 20:3 21:3 22:3 23:3 24:3 25:3 26:3 27:3 28:3 29:3 30:4 31:4 32:4 33:4 34:4 35:4 36:4 37:5 38:5 39:6 40:7 41:7 42:8 43:8 44:9 45:10 46:11 47:12 48:12 49:13 50:13 51:14 52:15 53:16 54:17 55:17 56:18 57:19 58:20 59:21 60:22 61:22 62:23 63:23 64:24 65:25 66:26 67:27 68:28 69:29 70:30 71:31 72:32 73:33 74:34 75:34 76:35 77:36 78:37 79:38 80:39 81:40 82:41 83:42 84:43 85:44 86:45 87:46 88:47 89:47 90:47 91:48 92:48 93:48 94:49 95:49 96:49 97:50 98:50 99:51 100:52 101:53 102:54 103:54 104:55 105:56 106:56 107:57 108:58 109:59 110:60 111:61 112:62 113:63 114:63 115:63 116:64 117:64 118:64 119:65 120:66 121:67 122:68 123:69 124:69 125:70 126:71 127:72 128:73 129:74 130:75 131:76 132:76 133:76 134:77 135:78 136:78 137:79 138:80 139:81 140:82 141:82 142:82 143:82 144:83 145:84 146:85 147:86 148:87 149:88 150:89 151:90 152:90 153:91 154:92 155:93 156:94 157:95 158:96 159:97 160:98 161:99 162:100 163:101 164:101 165:101 166:102 167:103 168:103 169:104 170:105 171:105 172:106 173:107 174:107 175:108 176:108 177:108\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   token_is_max_context: 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   input_ids: 101 2054 2001 1996 2171 1997 20773 1005 1055 2034 3948 2201 1029 102 20773 21025 19358 22815 1011 5708 1006 1013 12170 23432 29715 3501 29678 12325 29685 1013 10506 1011 10930 2078 1011 2360 1007 1006 2141 2244 1018 1010 3261 1007 2003 2019 2137 3220 1010 6009 1010 2501 3135 1998 3883 1012 2141 1998 2992 1999 5395 1010 3146 1010 2016 2864 1999 2536 4823 1998 5613 6479 2004 1037 2775 1010 1998 3123 2000 4476 1999 1996 2397 4134 2004 2599 3220 1997 1054 1004 1038 2611 1011 2177 10461 1005 1055 2775 1012 3266 2011 2014 2269 1010 25436 22815 1010 1996 2177 2150 2028 1997 1996 2088 1005 1055 2190 1011 4855 2611 2967 1997 2035 2051 1012 2037 14221 2387 1996 2713 1997 20773 1005 1055 2834 2201 1010 20754 1999 2293 1006 2494 1007 1010 2029 2511 2014 2004 1037 3948 3063 4969 1010 3687 2274 8922 2982 1998 2956 1996 4908 2980 2531 2193 1011 2028 3895 1000 4689 1999 2293 1000 1998 1000 3336 2879 1000 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   start_position: 137\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   end_position: 139\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   answer: dangerously in love\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   *** Example ***\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   unique_id: 1000000015\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   example_index: 15\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   doc_span_index: 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   tokens: [CLS] after her second solo album , what other entertainment venture did beyonce explore ? [SEP] following the di ##sb ##and ##ment of destiny ' s child in june 2005 , she released her second solo album , b ' day ( 2006 ) , which contained hits \" de ##ja vu \" , \" ir ##re ##pl ##ace ##able \" , and \" beautiful liar \" . beyonce also ventured into acting , with a golden globe - nominated performance in dream ##girl ##s ( 2006 ) , and starring roles in the pink panther ( 2006 ) and obsessed ( 2009 ) . her marriage to rapper jay z and portrayal of et ##ta james in cadillac records ( 2008 ) influenced her third album , i am . . . sasha fierce ( 2008 ) , which saw the birth of her alter - ego sasha fierce and earned a record - setting six grammy awards in 2010 , including song of the year for \" single ladies ( put a ring on it ) \" . beyonce took a hiatus from music in 2010 and took over management of her career ; her fourth album 4 ( 2011 ) was subsequently mel ##lowe ##r in tone , exploring 1970s funk , 1980s pop , and 1990s soul . her critically acclaimed fifth studio album , beyonce ( 2013 ) , was distinguished from previous releases by its experimental production and exploration of darker themes . [SEP]\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   token_to_orig_map: 16:0 17:1 18:2 19:2 20:2 21:2 22:3 23:4 24:4 25:4 26:5 27:6 28:7 29:8 30:8 31:9 32:10 33:11 34:12 35:13 36:14 37:14 38:15 39:15 40:15 41:16 42:16 43:16 44:16 45:17 46:18 47:19 48:20 49:20 50:20 51:21 52:21 53:21 54:22 55:22 56:22 57:22 58:22 59:22 60:22 61:22 62:23 63:24 64:24 65:25 66:25 67:25 68:26 69:27 70:28 71:29 72:30 73:30 74:31 75:32 76:33 77:34 78:34 79:34 80:35 81:36 82:37 83:37 84:37 85:38 86:38 87:38 88:38 89:39 90:40 91:41 92:42 93:43 94:44 95:45 96:46 97:46 98:46 99:47 100:48 101:49 102:49 103:49 104:49 105:50 106:51 107:52 108:53 109:54 110:55 111:56 112:57 113:58 114:59 115:59 116:60 117:61 118:62 119:63 120:64 121:64 122:64 123:65 124:66 125:67 126:68 127:68 128:69 129:70 130:70 131:70 132:70 133:71 134:72 135:73 136:73 137:73 138:73 139:74 140:75 141:76 142:77 143:78 144:79 145:80 146:80 147:80 148:81 149:82 150:83 151:84 152:85 153:86 154:86 155:86 156:87 157:88 158:89 159:90 160:91 161:91 162:92 163:93 164:94 165:95 166:96 167:97 168:98 169:98 170:99 171:100 172:100 173:101 174:102 175:103 176:104 177:104 178:104 179:104 180:105 181:106 182:107 183:108 184:109 185:110 186:111 187:112 188:113 189:114 190:115 191:116 192:117 193:118 194:119 195:119 196:120 197:121 198:122 199:123 200:124 201:124 202:124 203:125 204:126 205:127 206:127 207:127 208:128 209:129 210:129 211:130 212:131 213:132 214:132 215:133 216:134 217:134 218:135 219:136 220:137 221:137 222:138 223:139 224:140 225:141 226:142 227:143 228:143 229:144 230:145 231:145 232:145 233:145 234:146 235:147 236:148 237:149 238:150 239:151 240:152 241:153 242:154 243:155 244:156 245:157 246:158 247:159 248:159\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   token_is_max_context: 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   input_ids: 101 2044 2014 2117 3948 2201 1010 2054 2060 4024 6957 2106 20773 8849 1029 102 2206 1996 4487 19022 5685 3672 1997 10461 1005 1055 2775 1999 2238 2384 1010 2016 2207 2014 2117 3948 2201 1010 1038 1005 2154 1006 2294 1007 1010 2029 4838 4978 1000 2139 3900 24728 1000 1010 1000 20868 2890 24759 10732 3085 1000 1010 1998 1000 3376 16374 1000 1012 20773 2036 20510 2046 3772 1010 2007 1037 3585 7595 1011 4222 2836 1999 3959 15239 2015 1006 2294 1007 1010 1998 4626 4395 1999 1996 5061 15133 1006 2294 1007 1998 15896 1006 2268 1007 1012 2014 3510 2000 10687 6108 1062 1998 13954 1997 3802 2696 2508 1999 20425 2636 1006 2263 1007 5105 2014 2353 2201 1010 1045 2572 1012 1012 1012 14673 9205 1006 2263 1007 1010 2029 2387 1996 4182 1997 2014 11477 1011 13059 14673 9205 1998 3687 1037 2501 1011 4292 2416 8922 2982 1999 2230 1010 2164 2299 1997 1996 2095 2005 1000 2309 6456 1006 2404 1037 3614 2006 2009 1007 1000 1012 20773 2165 1037 14221 2013 2189 1999 2230 1998 2165 2058 2968 1997 2014 2476 1025 2014 2959 2201 1018 1006 2249 1007 2001 3525 11463 27663 2099 1999 4309 1010 11131 3955 11962 1010 3865 3769 1010 1998 4134 3969 1012 2014 11321 10251 3587 2996 2201 1010 20773 1006 2286 1007 1010 2001 5182 2013 3025 7085 2011 2049 6388 2537 1998 8993 1997 9904 6991 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   start_position: 72\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   end_position: 72\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   answer: acting\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   *** Example ***\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   unique_id: 1000000016\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   example_index: 16\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   doc_span_index: 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   tokens: [CLS] which artist did beyonce marry ? [SEP] following the di ##sb ##and ##ment of destiny ' s child in june 2005 , she released her second solo album , b ' day ( 2006 ) , which contained hits \" de ##ja vu \" , \" ir ##re ##pl ##ace ##able \" , and \" beautiful liar \" . beyonce also ventured into acting , with a golden globe - nominated performance in dream ##girl ##s ( 2006 ) , and starring roles in the pink panther ( 2006 ) and obsessed ( 2009 ) . her marriage to rapper jay z and portrayal of et ##ta james in cadillac records ( 2008 ) influenced her third album , i am . . . sasha fierce ( 2008 ) , which saw the birth of her alter - ego sasha fierce and earned a record - setting six grammy awards in 2010 , including song of the year for \" single ladies ( put a ring on it ) \" . beyonce took a hiatus from music in 2010 and took over management of her career ; her fourth album 4 ( 2011 ) was subsequently mel ##lowe ##r in tone , exploring 1970s funk , 1980s pop , and 1990s soul . her critically acclaimed fifth studio album , beyonce ( 2013 ) , was distinguished from previous releases by its experimental production and exploration of darker themes . [SEP]\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   token_to_orig_map: 8:0 9:1 10:2 11:2 12:2 13:2 14:3 15:4 16:4 17:4 18:5 19:6 20:7 21:8 22:8 23:9 24:10 25:11 26:12 27:13 28:14 29:14 30:15 31:15 32:15 33:16 34:16 35:16 36:16 37:17 38:18 39:19 40:20 41:20 42:20 43:21 44:21 45:21 46:22 47:22 48:22 49:22 50:22 51:22 52:22 53:22 54:23 55:24 56:24 57:25 58:25 59:25 60:26 61:27 62:28 63:29 64:30 65:30 66:31 67:32 68:33 69:34 70:34 71:34 72:35 73:36 74:37 75:37 76:37 77:38 78:38 79:38 80:38 81:39 82:40 83:41 84:42 85:43 86:44 87:45 88:46 89:46 90:46 91:47 92:48 93:49 94:49 95:49 96:49 97:50 98:51 99:52 100:53 101:54 102:55 103:56 104:57 105:58 106:59 107:59 108:60 109:61 110:62 111:63 112:64 113:64 114:64 115:65 116:66 117:67 118:68 119:68 120:69 121:70 122:70 123:70 124:70 125:71 126:72 127:73 128:73 129:73 130:73 131:74 132:75 133:76 134:77 135:78 136:79 137:80 138:80 139:80 140:81 141:82 142:83 143:84 144:85 145:86 146:86 147:86 148:87 149:88 150:89 151:90 152:91 153:91 154:92 155:93 156:94 157:95 158:96 159:97 160:98 161:98 162:99 163:100 164:100 165:101 166:102 167:103 168:104 169:104 170:104 171:104 172:105 173:106 174:107 175:108 176:109 177:110 178:111 179:112 180:113 181:114 182:115 183:116 184:117 185:118 186:119 187:119 188:120 189:121 190:122 191:123 192:124 193:124 194:124 195:125 196:126 197:127 198:127 199:127 200:128 201:129 202:129 203:130 204:131 205:132 206:132 207:133 208:134 209:134 210:135 211:136 212:137 213:137 214:138 215:139 216:140 217:141 218:142 219:143 220:143 221:144 222:145 223:145 224:145 225:145 226:146 227:147 228:148 229:149 230:150 231:151 232:152 233:153 234:154 235:155 236:156 237:157 238:158 239:159 240:159\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   input_ids: 101 2029 3063 2106 20773 5914 1029 102 2206 1996 4487 19022 5685 3672 1997 10461 1005 1055 2775 1999 2238 2384 1010 2016 2207 2014 2117 3948 2201 1010 1038 1005 2154 1006 2294 1007 1010 2029 4838 4978 1000 2139 3900 24728 1000 1010 1000 20868 2890 24759 10732 3085 1000 1010 1998 1000 3376 16374 1000 1012 20773 2036 20510 2046 3772 1010 2007 1037 3585 7595 1011 4222 2836 1999 3959 15239 2015 1006 2294 1007 1010 1998 4626 4395 1999 1996 5061 15133 1006 2294 1007 1998 15896 1006 2268 1007 1012 2014 3510 2000 10687 6108 1062 1998 13954 1997 3802 2696 2508 1999 20425 2636 1006 2263 1007 5105 2014 2353 2201 1010 1045 2572 1012 1012 1012 14673 9205 1006 2263 1007 1010 2029 2387 1996 4182 1997 2014 11477 1011 13059 14673 9205 1998 3687 1037 2501 1011 4292 2416 8922 2982 1999 2230 1010 2164 2299 1997 1996 2095 2005 1000 2309 6456 1006 2404 1037 3614 2006 2009 1007 1000 1012 20773 2165 1037 14221 2013 2189 1999 2230 1998 2165 2058 2968 1997 2014 2476 1025 2014 2959 2201 1018 1006 2249 1007 2001 3525 11463 27663 2099 1999 4309 1010 11131 3955 11962 1010 3865 3769 1010 1998 4134 3969 1012 2014 11321 10251 3587 2996 2201 1010 20773 1006 2286 1007 1010 2001 5182 2013 3025 7085 2011 2049 6388 2537 1998 8993 1997 9904 6991 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   start_position: 101\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   end_position: 102\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   answer: jay z\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   *** Example ***\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   unique_id: 1000000017\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   example_index: 17\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   doc_span_index: 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   tokens: [CLS] to set the record for grammy ##s , how many did beyonce win ? [SEP] following the di ##sb ##and ##ment of destiny ' s child in june 2005 , she released her second solo album , b ' day ( 2006 ) , which contained hits \" de ##ja vu \" , \" ir ##re ##pl ##ace ##able \" , and \" beautiful liar \" . beyonce also ventured into acting , with a golden globe - nominated performance in dream ##girl ##s ( 2006 ) , and starring roles in the pink panther ( 2006 ) and obsessed ( 2009 ) . her marriage to rapper jay z and portrayal of et ##ta james in cadillac records ( 2008 ) influenced her third album , i am . . . sasha fierce ( 2008 ) , which saw the birth of her alter - ego sasha fierce and earned a record - setting six grammy awards in 2010 , including song of the year for \" single ladies ( put a ring on it ) \" . beyonce took a hiatus from music in 2010 and took over management of her career ; her fourth album 4 ( 2011 ) was subsequently mel ##lowe ##r in tone , exploring 1970s funk , 1980s pop , and 1990s soul . her critically acclaimed fifth studio album , beyonce ( 2013 ) , was distinguished from previous releases by its experimental production and exploration of darker themes . [SEP]\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   token_to_orig_map: 16:0 17:1 18:2 19:2 20:2 21:2 22:3 23:4 24:4 25:4 26:5 27:6 28:7 29:8 30:8 31:9 32:10 33:11 34:12 35:13 36:14 37:14 38:15 39:15 40:15 41:16 42:16 43:16 44:16 45:17 46:18 47:19 48:20 49:20 50:20 51:21 52:21 53:21 54:22 55:22 56:22 57:22 58:22 59:22 60:22 61:22 62:23 63:24 64:24 65:25 66:25 67:25 68:26 69:27 70:28 71:29 72:30 73:30 74:31 75:32 76:33 77:34 78:34 79:34 80:35 81:36 82:37 83:37 84:37 85:38 86:38 87:38 88:38 89:39 90:40 91:41 92:42 93:43 94:44 95:45 96:46 97:46 98:46 99:47 100:48 101:49 102:49 103:49 104:49 105:50 106:51 107:52 108:53 109:54 110:55 111:56 112:57 113:58 114:59 115:59 116:60 117:61 118:62 119:63 120:64 121:64 122:64 123:65 124:66 125:67 126:68 127:68 128:69 129:70 130:70 131:70 132:70 133:71 134:72 135:73 136:73 137:73 138:73 139:74 140:75 141:76 142:77 143:78 144:79 145:80 146:80 147:80 148:81 149:82 150:83 151:84 152:85 153:86 154:86 155:86 156:87 157:88 158:89 159:90 160:91 161:91 162:92 163:93 164:94 165:95 166:96 167:97 168:98 169:98 170:99 171:100 172:100 173:101 174:102 175:103 176:104 177:104 178:104 179:104 180:105 181:106 182:107 183:108 184:109 185:110 186:111 187:112 188:113 189:114 190:115 191:116 192:117 193:118 194:119 195:119 196:120 197:121 198:122 199:123 200:124 201:124 202:124 203:125 204:126 205:127 206:127 207:127 208:128 209:129 210:129 211:130 212:131 213:132 214:132 215:133 216:134 217:134 218:135 219:136 220:137 221:137 222:138 223:139 224:140 225:141 226:142 227:143 228:143 229:144 230:145 231:145 232:145 233:145 234:146 235:147 236:148 237:149 238:150 239:151 240:152 241:153 242:154 243:155 244:156 245:157 246:158 247:159 248:159\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   token_is_max_context: 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   input_ids: 101 2000 2275 1996 2501 2005 8922 2015 1010 2129 2116 2106 20773 2663 1029 102 2206 1996 4487 19022 5685 3672 1997 10461 1005 1055 2775 1999 2238 2384 1010 2016 2207 2014 2117 3948 2201 1010 1038 1005 2154 1006 2294 1007 1010 2029 4838 4978 1000 2139 3900 24728 1000 1010 1000 20868 2890 24759 10732 3085 1000 1010 1998 1000 3376 16374 1000 1012 20773 2036 20510 2046 3772 1010 2007 1037 3585 7595 1011 4222 2836 1999 3959 15239 2015 1006 2294 1007 1010 1998 4626 4395 1999 1996 5061 15133 1006 2294 1007 1998 15896 1006 2268 1007 1012 2014 3510 2000 10687 6108 1062 1998 13954 1997 3802 2696 2508 1999 20425 2636 1006 2263 1007 5105 2014 2353 2201 1010 1045 2572 1012 1012 1012 14673 9205 1006 2263 1007 1010 2029 2387 1996 4182 1997 2014 11477 1011 13059 14673 9205 1998 3687 1037 2501 1011 4292 2416 8922 2982 1999 2230 1010 2164 2299 1997 1996 2095 2005 1000 2309 6456 1006 2404 1037 3614 2006 2009 1007 1000 1012 20773 2165 1037 14221 2013 2189 1999 2230 1998 2165 2058 2968 1997 2014 2476 1025 2014 2959 2201 1018 1006 2249 1007 2001 3525 11463 27663 2099 1999 4309 1010 11131 3955 11962 1010 3865 3769 1010 1998 4134 3969 1012 2014 11321 10251 3587 2996 2201 1010 20773 1006 2286 1007 1010 2001 5182 2013 3025 7085 2011 2049 6388 2537 1998 8993 1997 9904 6991 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   start_position: 156\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   end_position: 156\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   answer: six\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   *** Example ***\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   unique_id: 1000000018\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   example_index: 18\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   doc_span_index: 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   tokens: [CLS] for what movie did beyonce receive her first golden globe nomination ? [SEP] following the di ##sb ##and ##ment of destiny ' s child in june 2005 , she released her second solo album , b ' day ( 2006 ) , which contained hits \" de ##ja vu \" , \" ir ##re ##pl ##ace ##able \" , and \" beautiful liar \" . beyonce also ventured into acting , with a golden globe - nominated performance in dream ##girl ##s ( 2006 ) , and starring roles in the pink panther ( 2006 ) and obsessed ( 2009 ) . her marriage to rapper jay z and portrayal of et ##ta james in cadillac records ( 2008 ) influenced her third album , i am . . . sasha fierce ( 2008 ) , which saw the birth of her alter - ego sasha fierce and earned a record - setting six grammy awards in 2010 , including song of the year for \" single ladies ( put a ring on it ) \" . beyonce took a hiatus from music in 2010 and took over management of her career ; her fourth album 4 ( 2011 ) was subsequently mel ##lowe ##r in tone , exploring 1970s funk , 1980s pop , and 1990s soul . her critically acclaimed fifth studio album , beyonce ( 2013 ) , was distinguished from previous releases by its experimental production and exploration of darker themes . [SEP]\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   token_to_orig_map: 14:0 15:1 16:2 17:2 18:2 19:2 20:3 21:4 22:4 23:4 24:5 25:6 26:7 27:8 28:8 29:9 30:10 31:11 32:12 33:13 34:14 35:14 36:15 37:15 38:15 39:16 40:16 41:16 42:16 43:17 44:18 45:19 46:20 47:20 48:20 49:21 50:21 51:21 52:22 53:22 54:22 55:22 56:22 57:22 58:22 59:22 60:23 61:24 62:24 63:25 64:25 65:25 66:26 67:27 68:28 69:29 70:30 71:30 72:31 73:32 74:33 75:34 76:34 77:34 78:35 79:36 80:37 81:37 82:37 83:38 84:38 85:38 86:38 87:39 88:40 89:41 90:42 91:43 92:44 93:45 94:46 95:46 96:46 97:47 98:48 99:49 100:49 101:49 102:49 103:50 104:51 105:52 106:53 107:54 108:55 109:56 110:57 111:58 112:59 113:59 114:60 115:61 116:62 117:63 118:64 119:64 120:64 121:65 122:66 123:67 124:68 125:68 126:69 127:70 128:70 129:70 130:70 131:71 132:72 133:73 134:73 135:73 136:73 137:74 138:75 139:76 140:77 141:78 142:79 143:80 144:80 145:80 146:81 147:82 148:83 149:84 150:85 151:86 152:86 153:86 154:87 155:88 156:89 157:90 158:91 159:91 160:92 161:93 162:94 163:95 164:96 165:97 166:98 167:98 168:99 169:100 170:100 171:101 172:102 173:103 174:104 175:104 176:104 177:104 178:105 179:106 180:107 181:108 182:109 183:110 184:111 185:112 186:113 187:114 188:115 189:116 190:117 191:118 192:119 193:119 194:120 195:121 196:122 197:123 198:124 199:124 200:124 201:125 202:126 203:127 204:127 205:127 206:128 207:129 208:129 209:130 210:131 211:132 212:132 213:133 214:134 215:134 216:135 217:136 218:137 219:137 220:138 221:139 222:140 223:141 224:142 225:143 226:143 227:144 228:145 229:145 230:145 231:145 232:146 233:147 234:148 235:149 236:150 237:151 238:152 239:153 240:154 241:155 242:156 243:157 244:158 245:159 246:159\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   token_is_max_context: 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   input_ids: 101 2005 2054 3185 2106 20773 4374 2014 2034 3585 7595 6488 1029 102 2206 1996 4487 19022 5685 3672 1997 10461 1005 1055 2775 1999 2238 2384 1010 2016 2207 2014 2117 3948 2201 1010 1038 1005 2154 1006 2294 1007 1010 2029 4838 4978 1000 2139 3900 24728 1000 1010 1000 20868 2890 24759 10732 3085 1000 1010 1998 1000 3376 16374 1000 1012 20773 2036 20510 2046 3772 1010 2007 1037 3585 7595 1011 4222 2836 1999 3959 15239 2015 1006 2294 1007 1010 1998 4626 4395 1999 1996 5061 15133 1006 2294 1007 1998 15896 1006 2268 1007 1012 2014 3510 2000 10687 6108 1062 1998 13954 1997 3802 2696 2508 1999 20425 2636 1006 2263 1007 5105 2014 2353 2201 1010 1045 2572 1012 1012 1012 14673 9205 1006 2263 1007 1010 2029 2387 1996 4182 1997 2014 11477 1011 13059 14673 9205 1998 3687 1037 2501 1011 4292 2416 8922 2982 1999 2230 1010 2164 2299 1997 1996 2095 2005 1000 2309 6456 1006 2404 1037 3614 2006 2009 1007 1000 1012 20773 2165 1037 14221 2013 2189 1999 2230 1998 2165 2058 2968 1997 2014 2476 1025 2014 2959 2201 1018 1006 2249 1007 2001 3525 11463 27663 2099 1999 4309 1010 11131 3955 11962 1010 3865 3769 1010 1998 4134 3969 1012 2014 11321 10251 3587 2996 2201 1010 20773 1006 2286 1007 1010 2001 5182 2013 3025 7085 2011 2049 6388 2537 1998 8993 1997 9904 6991 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   start_position: 80\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   end_position: 82\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   answer: dream ##girl ##s\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   *** Example ***\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   unique_id: 1000000019\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   example_index: 19\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   doc_span_index: 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   tokens: [CLS] when did beyonce take a hiatus in her career and take control of her management ? [SEP] following the di ##sb ##and ##ment of destiny ' s child in june 2005 , she released her second solo album , b ' day ( 2006 ) , which contained hits \" de ##ja vu \" , \" ir ##re ##pl ##ace ##able \" , and \" beautiful liar \" . beyonce also ventured into acting , with a golden globe - nominated performance in dream ##girl ##s ( 2006 ) , and starring roles in the pink panther ( 2006 ) and obsessed ( 2009 ) . her marriage to rapper jay z and portrayal of et ##ta james in cadillac records ( 2008 ) influenced her third album , i am . . . sasha fierce ( 2008 ) , which saw the birth of her alter - ego sasha fierce and earned a record - setting six grammy awards in 2010 , including song of the year for \" single ladies ( put a ring on it ) \" . beyonce took a hiatus from music in 2010 and took over management of her career ; her fourth album 4 ( 2011 ) was subsequently mel ##lowe ##r in tone , exploring 1970s funk , 1980s pop , and 1990s soul . her critically acclaimed fifth studio album , beyonce ( 2013 ) , was distinguished from previous releases by its experimental production and exploration of darker themes . [SEP]\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   token_to_orig_map: 18:0 19:1 20:2 21:2 22:2 23:2 24:3 25:4 26:4 27:4 28:5 29:6 30:7 31:8 32:8 33:9 34:10 35:11 36:12 37:13 38:14 39:14 40:15 41:15 42:15 43:16 44:16 45:16 46:16 47:17 48:18 49:19 50:20 51:20 52:20 53:21 54:21 55:21 56:22 57:22 58:22 59:22 60:22 61:22 62:22 63:22 64:23 65:24 66:24 67:25 68:25 69:25 70:26 71:27 72:28 73:29 74:30 75:30 76:31 77:32 78:33 79:34 80:34 81:34 82:35 83:36 84:37 85:37 86:37 87:38 88:38 89:38 90:38 91:39 92:40 93:41 94:42 95:43 96:44 97:45 98:46 99:46 100:46 101:47 102:48 103:49 104:49 105:49 106:49 107:50 108:51 109:52 110:53 111:54 112:55 113:56 114:57 115:58 116:59 117:59 118:60 119:61 120:62 121:63 122:64 123:64 124:64 125:65 126:66 127:67 128:68 129:68 130:69 131:70 132:70 133:70 134:70 135:71 136:72 137:73 138:73 139:73 140:73 141:74 142:75 143:76 144:77 145:78 146:79 147:80 148:80 149:80 150:81 151:82 152:83 153:84 154:85 155:86 156:86 157:86 158:87 159:88 160:89 161:90 162:91 163:91 164:92 165:93 166:94 167:95 168:96 169:97 170:98 171:98 172:99 173:100 174:100 175:101 176:102 177:103 178:104 179:104 180:104 181:104 182:105 183:106 184:107 185:108 186:109 187:110 188:111 189:112 190:113 191:114 192:115 193:116 194:117 195:118 196:119 197:119 198:120 199:121 200:122 201:123 202:124 203:124 204:124 205:125 206:126 207:127 208:127 209:127 210:128 211:129 212:129 213:130 214:131 215:132 216:132 217:133 218:134 219:134 220:135 221:136 222:137 223:137 224:138 225:139 226:140 227:141 228:142 229:143 230:143 231:144 232:145 233:145 234:145 235:145 236:146 237:147 238:148 239:149 240:150 241:151 242:152 243:153 244:154 245:155 246:156 247:157 248:158 249:159 250:159\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   token_is_max_context: 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   input_ids: 101 2043 2106 20773 2202 1037 14221 1999 2014 2476 1998 2202 2491 1997 2014 2968 1029 102 2206 1996 4487 19022 5685 3672 1997 10461 1005 1055 2775 1999 2238 2384 1010 2016 2207 2014 2117 3948 2201 1010 1038 1005 2154 1006 2294 1007 1010 2029 4838 4978 1000 2139 3900 24728 1000 1010 1000 20868 2890 24759 10732 3085 1000 1010 1998 1000 3376 16374 1000 1012 20773 2036 20510 2046 3772 1010 2007 1037 3585 7595 1011 4222 2836 1999 3959 15239 2015 1006 2294 1007 1010 1998 4626 4395 1999 1996 5061 15133 1006 2294 1007 1998 15896 1006 2268 1007 1012 2014 3510 2000 10687 6108 1062 1998 13954 1997 3802 2696 2508 1999 20425 2636 1006 2263 1007 5105 2014 2353 2201 1010 1045 2572 1012 1012 1012 14673 9205 1006 2263 1007 1010 2029 2387 1996 4182 1997 2014 11477 1011 13059 14673 9205 1998 3687 1037 2501 1011 4292 2416 8922 2982 1999 2230 1010 2164 2299 1997 1996 2095 2005 1000 2309 6456 1006 2404 1037 3614 2006 2009 1007 1000 1012 20773 2165 1037 14221 2013 2189 1999 2230 1998 2165 2058 2968 1997 2014 2476 1025 2014 2959 2201 1018 1006 2249 1007 2001 3525 11463 27663 2099 1999 4309 1010 11131 3955 11962 1010 3865 3769 1010 1998 4134 3969 1012 2014 11321 10251 3587 2996 2201 1010 20773 1006 2286 1007 1010 2001 5182 2013 3025 7085 2011 2049 6388 2537 1998 8993 1997 9904 6991 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   start_position: 162\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   end_position: 162\n",
            "04/23/2020 18:21:46 - INFO - utils_squad -   answer: 2010\n",
            "04/23/2020 18:35:31 - INFO - __main__ -   Saving features into cached file /content/drive/My Drive/cached_train_bert-large-uncased-whole-word-masking_384\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
            "\n",
            "Defaults for this optimization level are:\n",
            "enabled                : True\n",
            "opt_level              : O1\n",
            "cast_model_type        : None\n",
            "patch_torch_functions  : True\n",
            "keep_batchnorm_fp32    : None\n",
            "master_weights         : None\n",
            "loss_scale             : dynamic\n",
            "Processing user overrides (additional kwargs that are not None)...\n",
            "After processing overrides, optimization options are:\n",
            "enabled                : True\n",
            "opt_level              : O1\n",
            "cast_model_type        : None\n",
            "patch_torch_functions  : True\n",
            "keep_batchnorm_fp32    : None\n",
            "master_weights         : None\n",
            "loss_scale             : dynamic\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-ca420a2f0251>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-34-ca420a2f0251>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_and_cache_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" global_step = %s, average loss = %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-ba20029bc9e8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, train_dataset, model, tokenizer)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16_opt_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;31m#model = TransformerModel('bert', 'bert-base-cased', use_cuda=False, args={'fp16': False})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/apex/amp/frontend.py\u001b[0m in \u001b[0;36minitialize\u001b[0;34m(models, optimizers, enabled, opt_level, cast_model_type, patch_torch_functions, keep_batchnorm_fp32, master_weights, loss_scale, cast_model_outputs, num_losses, verbosity, min_loss_scale, max_loss_scale)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mmaybe_print\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{:22} : {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_amp_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt_properties\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcast_model_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/apex/amp/_initialize.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(models, optimizers, properties, num_losses, cast_model_outputs)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_amp_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_incoming_model_not_fp32\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0mcheck_params_fp32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;31m# In the future, when FP16_Optimizer can be deprecated and master weights can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/apex/amp/_initialize.py\u001b[0m in \u001b[0;36mcheck_params_fp32\u001b[0;34m(models)\u001b[0m\n\u001b[1;32m     91\u001b[0m                         \u001b[0;34m\"located on a CUDA device before passing it no matter what optimization level\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                         \"you chose. Use model.to('cuda') to use the default device.\".format(\n\u001b[0;32m---> 93\u001b[0;31m                         name, param.type()))\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;31m# Backward compatibility for PyTorch 0.4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/apex/amp/_amp_state.py\u001b[0m in \u001b[0;36mwarn_or_err\u001b[0;34m(msg)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Warning:  \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;31m# I'm not sure if allowing hard_override is a good idea.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# + \"  If you're sure you know what you're doing, supply \" +\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found param bert.embeddings.word_embeddings.weight with type torch.FloatTensor, expected torch.cuda.FloatTensor.\nWhen using amp.initialize, you need to provide a model with parameters\nlocated on a CUDA device before passing it no matter what optimization level\nyou chose. Use model.to('cuda') to use the default device."
          ]
        }
      ]
    }
  ]
}